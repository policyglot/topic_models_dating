{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Filter\n",
    "### The purpose of this notebook is four-fold:\n",
    "1) Filter data to only the relevant rows\n",
    "\n",
    "2) Delete the unnecessary columns\n",
    "\n",
    "3) Suitably edit the text to allow for topic modeling\n",
    "\n",
    "4) Create new variables to assist with demographic comparisons of topics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "# For Data Cleaning\n",
    "from bs4 import BeautifulSoup\n",
    "from split_utils import *\n",
    "from text_complexity_utils import get_npoly, get_flesch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in raw data\n",
    "df = pd.read_csv('../profiles.csv/profiles.csv')\n",
    "#correct subset of data\n",
    "df = df[(df['sex']==\"m\")\n",
    "        &(df['orientation']==\"straight\") \n",
    "        & (df['status']==\"single\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29163, 31)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 29163/29163 [00:12<00:00, 2302.66it/s]\n"
     ]
    }
   ],
   "source": [
    "# Some of the essays have just a link in the text. BeautifulSoup sees that and gets \n",
    "# the wrong idea. This line hides those warnings.\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='bs4')\n",
    "def clean(text):\n",
    "    \"\"\"\n",
    "    Takes in raw text of essays\n",
    "    Removes all null values and url links\n",
    "    \n",
    "    Parameters\n",
    "    ---------\n",
    "    text: string\n",
    "        Usually, this is the raw profile essay \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    t: string\n",
    "        This refers to the cleaned profile essay\n",
    "    \"\"\"\n",
    "    if pd.isnull(text):\n",
    "        t = np.nan\n",
    "    else:\n",
    "        t = BeautifulSoup(text, 'lxml').get_text()\n",
    "        t = t.lower()\n",
    "        t = t.strip().replace('\\n','').replace(\"\\r\", \" \").replace('\\t', '')\n",
    "        bad_words = ['http', 'www', '\\nnan']\n",
    "\n",
    "        for b in bad_words:\n",
    "            t = t.replace(b, '')\n",
    "    #After these subsitutions, the string may become empty\n",
    "    if t == '':\n",
    "        t = np.nan\n",
    "    \n",
    "    return t\n",
    "\n",
    "#Clearing out all HTML and unnecessary characters\n",
    "df['essay0'] = df['essay0'].progress_apply(clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables of interest are categorical, and therefore not easily imputed. \n",
    "It may be possible to impute missing height. But the remaining categorical values in the data bear no causal relationship with height. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Focus on the chosen variables of importance and the essay\n",
    "must_haves = ['body_type', 'height', 'education', 'ethnicity', 'sex', 'essay0']\n",
    "#drop the rest\n",
    "df = df[must_haves]\n",
    "#drop null values\n",
    "df = df.dropna(subset= must_haves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20576, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATING NEW COLUMNS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of the sections here are taken directly from the following link, with specific modifications\n",
    "Taken directly from:\n",
    "https://github.com/UM-CSS/CSSLabs-NLP/blob/master/1_Data_munging.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recode(text, dictionary, default=np.nan):\n",
    "    \"\"\"\n",
    "    Function for recoding categories in a column based on exact matches\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    text: a string\n",
    "    \n",
    "    dictionary: dictionary\n",
    "        contains desired values as keys, and all the\n",
    "        labels to be matched with it used as values\n",
    "    \n",
    "    default: string or None\n",
    "        the value to be used if no match is found with the \n",
    "        dictionary keys\n",
    "    \n",
    "    Returns\n",
    "    ------\n",
    "    out: a string or None\n",
    "    \n",
    "    \"\"\"\n",
    "    out = default\n",
    "    text = str(text)\n",
    "    \n",
    "    for x in dictionary.keys():\n",
    "        for y in dictionary[x]:\n",
    "            if y == text: #exact match\n",
    "                out = x\n",
    "                return out\n",
    "    return out\n",
    "\n",
    "#Might be possible to refactor this function out completely\n",
    "def recode_fuzzy(text, dictionary, default=np.nan):\n",
    "    \"\"\"\n",
    "    Function for recoding categories in a column based on partial matches\n",
    "    \n",
    "    text: a string\n",
    "    \n",
    "    dictionary: dictionary\n",
    "        contains desired values as keys, and all the\n",
    "        labels to be matched with it used as values\n",
    "    \n",
    "    default: string or None\n",
    "        the value to be used if no match is found with the \n",
    "        dictionary keys\n",
    "        \n",
    "    Returns\n",
    "    ------\n",
    "    out: a string or None\n",
    "\n",
    "    \"\"\"\n",
    "    out = default\n",
    "    text = str(text)\n",
    "    \n",
    "    for x in dictionary.keys():\n",
    "        for y in dictionary[x]:\n",
    "            if y in text: #partial match\n",
    "                out = x\n",
    "                return out\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tese dictionaries were created from all the observed unique values\n",
    "\n",
    "#Education\n",
    "ed_levels = {'High School or less': ['dropped out of high school', 'working on high school','graduated from high school', 'working on college/university', \n",
    "                    'two-year college', 'dropped out of college/university', \n",
    "                    'high school'], \n",
    "             'More than High School': ['graduated from college/university', \n",
    "                    'working on masters program', 'working on ph.d program', \n",
    "                    'college/university', 'working on law school', \n",
    "                    'dropped out of masters program', \n",
    "                    'dropped out of ph.d program', 'dropped out of law school', \n",
    "                    'dropped out of med school',\n",
    "                    'graduated from masters program',\n",
    "                    'graduated from ph.d program',                           \n",
    "                    'graduated from law school', \n",
    "                    'graduated from med school', 'masters program', \n",
    "                    'ph.d program', 'law school', 'med school']}\n",
    "\n",
    "#body type\n",
    "bodies = {'fit': ['fit', 'athletic', 'jacked'], \n",
    "          'not_fit': ['average', 'thin', 'skinny','curvey', 'a little extra', \n",
    "                      'full figured', 'overweight', 'rather not say', 'used up']\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['edu'] = df.education.apply(recode, dictionary=ed_levels, \n",
    "                                            default='unknown')\n",
    "df['fit'] = df.body_type.apply(recode, dictionary=bodies, \n",
    "                                            default='unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# race/ethnicity for exact matching\n",
    "ethn = {'White': ['white', 'middle eastern', 'middle eastern, white'], \n",
    "        'Asian': ['asian', 'indian', 'asian, pacific islander'], \n",
    "        'Black': ['black']\n",
    "       }   \n",
    "\n",
    "# race/ethnicityfor fuzzy matching\n",
    "ethn2 = {'Latinx': ['latin'], \n",
    "         'multiple': [','], \n",
    "         np.nan: ['nan']\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def census_2010_ethnicity(t):\n",
    "    '''\n",
    "    recodes ethnicity variables according to census categories\n",
    "    This conversion happens through dictionaries declared in the\n",
    "    previous cell. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    t- string\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    e- string\n",
    "    '''\n",
    "    text = str(t)\n",
    "    e = recode(text, ethn, default='other')\n",
    "    if 'other' == e:\n",
    "        e = recode_fuzzy(text, ethn2, default='other')\n",
    "    return e\n",
    "\n",
    "df['race_ethnicity'] = df.ethnicity.apply(census_2010_ethnicity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#there may be some way to build in the calculation of the first quartile\n",
    "def height_check(inches):\n",
    "    \"\"\"\n",
    "    takes in height and returns a label of short or not short\n",
    "    uses the first quartile as the cutoff for not being short\n",
    "    \n",
    "    parameters\n",
    "    ----------\n",
    "    inches: float\n",
    "        The height of the user in inches\n",
    "    \n",
    "    returns\n",
    "    ------\n",
    "    h: string\n",
    "        A label- 'short' or 'not short'\n",
    "    \n",
    "    \"\"\"\n",
    "    h = 'not_short'\n",
    "    if inches <= 69:\n",
    "        #This number was extracted as the first quartile of the distribution of height\n",
    "        h = 'short'\n",
    "    return h\n",
    "df['height'] = pd.to_numeric(df['height'])\n",
    "df['height_group'] = df.height.apply(height_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now drop the original variables\n",
    "df.drop(columns=['body_type', 'ethnicity','height','education'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('profiles_filtered.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROFILE LENGTH AND VARIABLES OF INTEREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By Ethnicity\n",
    "sns_race_plot = sns.boxplot(x=\"race_ethnicity\", y=\"profile_length\", data=df)\n",
    "sns_race_plot.set(title = 'Racial Background and Length of Dating Profile', \n",
    "                  xlabel = 'Race', ylabel = 'Number of Words')\n",
    "sns_race_plot.figure.savefig('profile_race.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By Education \n",
    "sns_plot = sns.boxplot(x=\"edu\", y=\"profile_length\", data=df)\n",
    "sns_plot.set(title = 'Education and Length of Dating Profile', \n",
    "                                                           xlabel = 'Education', \n",
    "                                                           ylabel = 'Number of Words' )\n",
    "sns_plot.figure.savefig('profile_educ.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By Height \n",
    "sns_plot = sns.boxplot(x=\"height_group, y=\"profile_length\", data=df)\n",
    "sns_plot.set(title = 'Height and Length of Dating Profile', \n",
    "                                                           xlabel = 'Height', \n",
    "                                                           ylabel = 'Number of Words' )\n",
    "sns_plot.figure.savefig('profile_height.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By Ditness Level\n",
    "sns_plot = sns.boxplot(x=\"fit, y=\"profile_length\", data=df)\n",
    "sns_plot.set(title = 'Fitness and Length of Dating Profile', \n",
    "                                                           xlabel = 'Height', \n",
    "                                                           ylabel = 'Number of Words' )\n",
    "sns_plot.figure.savefig('profile_fitness.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEXT EDITING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 20576/20576 [79:41:19<00:00, 10.85s/it]"
     ]
    }
   ],
   "source": [
    "# First, fix conjoined words in the essay\n",
    "# This may take up to 10 minutes\n",
    "df['essay0'] = df['essay0'].progress_apply(split_incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['long_words'] = df['essay0'].progress_apply(get_npoly)\n",
    "df['flesch'] = df['essay0'].progress_apply(get_flesch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this will the main data file for the rest of the analysis\n",
    "df.to_csv('compressed_okcupid.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
