{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Filter\n",
    "### The purpose of this notebook is four-fold:\n",
    "1) Filter data to only the relevant rows\n",
    "\n",
    "2) Delete the unnecessary columns\n",
    "\n",
    "3) Suitably edit the text to allow for topic modeling\n",
    "\n",
    "4) Create new variables to assist with demographic comparisons of topics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to apply the CRISP-DM Framework for Data Analysis here (as outlined here:\n",
    "https://www.datascience-pm.com/crisp-dm-2/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Business understanding – What does the business need?*\n",
    "The business, in this case, is OkCupid, and it might be facing a large number of men dropping out of the system because of high competition and limited responses. We cannot confirm this directly with OkCupid, but we do know that self-representation through online dating is a relatively new skill to gain in our species' long and checkered history. So why not provide some guidance along the way? The goal would be to provide data-driven guidance to male users of the service so that they stand out from the competition and get matched more often. This will increase the rating of the app, and lead to more sign-ups and revenue. \n",
    "\n",
    "Getting present-day data would be challenging. Many researchers have gained access to profiles and conversation data, but usually have the funding support and credentials of their universities to back them. Moreover, online dating data involves considerable privacy concerns. In such a situation, it would be best to acquire a low-cost data set that anonymizes data, but need not include all aspects of profiles or even be up-to-date. \n",
    "\n",
    "Success for us would involve first testing for the extent of homogeneity in dating profiles, and then providing support with helpful UX features that provide tips to remove that homeogeneity and sound memorable vis-a-vis other users. In technical terms, this means identifying from text the most common topics, language patterns and keywords, and then providing guidance to prevent such repetition. It would also be useful to check if these patterns vary in different subgroups of users, as indicated by variables like height, weight/fitness level, race and education level. \n",
    "\n",
    "Given these objectives, we will be proceeding with using Python and R (depending on which of them contains the most suitable packages for our specific and evolving tasks)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Preparation – How do we organize the data for modeling?**\n",
    "\n",
    "Fortunately, this is our sole dataset and does not seem to require any form of integration\n",
    "\n",
    "**Select Data: Determine which data sets will be used and document reasons for inclusion/exclusion.**\n",
    "   \n",
    "   \n",
    "**Clean Data**   \n",
    "    \n",
    "    Clean data: Often this is the lengthiest task. Without it, you’ll likely fall victim to garbage-in, garbage-out. A common practice during this task is to correct, impute, or remove erroneous values.\n",
    "    \n",
    "    Construct data: Derive new attributes that will be helpful. For example, derive someone’s body mass index from height and weight fields.\n",
    "    \n",
    "    Integrate data: Create new data sets by combining data from multiple sources.\n",
    "    \n",
    "    Format data: Re-format data as necessary. For example, you might convert string values that store numbers to numeric values so that you can perform mathematical operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Modeling – What modeling techniques should we apply?**\n",
    "\n",
    "We are focused on different versions of topic models here. One choice is between the commonly used Latent Dirichlet Allocation (LDA). This model is advantageous because it can be built on for more complex models, such as Structural Topic Models. \n",
    "\n",
    "On the other hand, the alternative Non-Negative Matrix Factorization model may be useful too, and has been shown to offer many advantages over LDA when dealing with very short documents such as SMS and Tweets (see references in Thesis- linked in the readme). Fortunately, these methods do not require test-training-validation splits. \n",
    "\n",
    "We will need to check how these models play out on our data, and choose accordingly. However, a priori, it seems like LDA would be more useful as it allows for using Structural Topic Models using existing modules in R. No such module currently exists in Python or R for NMF. \n",
    "\n",
    "We will also need to test for clustering of the profiles through unsupervised learning methods. We will begin with the standard K-Means clustering, and explore alternatives based on the results.  \n",
    "\n",
    "\n",
    "    Select modeling techniques: Determine which algorithms to try (e.g. regression, neural net).\n",
    "    Generate test design: Pending your modeling approach, you might need to split the data into training, test, and validation sets.\n",
    "    Fortuntely, this approach of topic models does not require test and training data. \n",
    "    \n",
    "    \n",
    "    Build model: As glamorous as this might sound, this might just be executing a few lines of code like “reg = LinearRegression().fit(X, y)”.\n",
    "    \n",
    "    \n",
    "    Assess model: Generally, multiple models are competing against each other, and the data scientist needs to interpret the model results based on domain knowledge, the pre-defined success criteria, and the test design."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation – Which model best meets the business objectives?\n",
    "\n",
    "    Evaluate results: Do the models meet the business success criteria? Which one(s) should we approve for the business?\n",
    "    Review process: Review the work accomplished. Was anything overlooked? Were all steps properly executed? Summarize findings and correct anything if needed.\n",
    "    Determine next steps: Based on the previous three tasks, determine whether to proceed to deployment, iterate further, or initiate new projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Deployment – How do stakeholders access the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data understanding – What data do we have / need? Is it clean?**\n",
    "Collect initial data: \n",
    "Acquire the necessary data and (if necessary) load it into your analysis tool.\n",
    "\n",
    "Describe data: Examine the data and document its surface properties like data format, number of records, or field identities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "# For Data Cleaning\n",
    "from bs4 import BeautifulSoup\n",
    "from split_utils import *\n",
    "from text_complexity_utils import get_npoly, get_flesch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>body_type</th>\n",
       "      <th>diet</th>\n",
       "      <th>drinks</th>\n",
       "      <th>drugs</th>\n",
       "      <th>education</th>\n",
       "      <th>essay0</th>\n",
       "      <th>essay1</th>\n",
       "      <th>essay2</th>\n",
       "      <th>essay3</th>\n",
       "      <th>...</th>\n",
       "      <th>location</th>\n",
       "      <th>offspring</th>\n",
       "      <th>orientation</th>\n",
       "      <th>pets</th>\n",
       "      <th>religion</th>\n",
       "      <th>sex</th>\n",
       "      <th>sign</th>\n",
       "      <th>smokes</th>\n",
       "      <th>speaks</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>a little extra</td>\n",
       "      <td>strictly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>about me:&lt;br /&gt;\\n&lt;br /&gt;\\ni would love to think...</td>\n",
       "      <td>currently working as an international agent fo...</td>\n",
       "      <td>making people laugh.&lt;br /&gt;\\nranting about a go...</td>\n",
       "      <td>the way i look. i am a six foot half asian, ha...</td>\n",
       "      <td>...</td>\n",
       "      <td>south san francisco, california</td>\n",
       "      <td>doesn&amp;rsquo;t have kids, but might want them</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism and very serious about it</td>\n",
       "      <td>m</td>\n",
       "      <td>gemini</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>english</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>average</td>\n",
       "      <td>mostly other</td>\n",
       "      <td>often</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>working on space camp</td>\n",
       "      <td>i am a chef: this is what that means.&lt;br /&gt;\\n1...</td>\n",
       "      <td>dedicating everyday to being an unbelievable b...</td>\n",
       "      <td>being silly. having ridiculous amonts of fun w...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>oakland, california</td>\n",
       "      <td>doesn&amp;rsquo;t have kids, but might want them</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism but not too serious about it</td>\n",
       "      <td>m</td>\n",
       "      <td>cancer</td>\n",
       "      <td>no</td>\n",
       "      <td>english (fluently), spanish (poorly), french (...</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>thin</td>\n",
       "      <td>anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>graduated from masters program</td>\n",
       "      <td>i'm not ashamed of much, but writing public te...</td>\n",
       "      <td>i make nerdy software for musicians, artists, ...</td>\n",
       "      <td>improvising in different contexts. alternating...</td>\n",
       "      <td>my large jaw and large glasses are the physica...</td>\n",
       "      <td>...</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>NaN</td>\n",
       "      <td>straight</td>\n",
       "      <td>has cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>pisces but it doesn&amp;rsquo;t matter</td>\n",
       "      <td>no</td>\n",
       "      <td>english, french, c++</td>\n",
       "      <td>available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>thin</td>\n",
       "      <td>vegetarian</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>i work in a library and go to school. . .</td>\n",
       "      <td>reading things written by old dead people</td>\n",
       "      <td>playing synthesizers and organizing books acco...</td>\n",
       "      <td>socially awkward but i do my best</td>\n",
       "      <td>...</td>\n",
       "      <td>berkeley, california</td>\n",
       "      <td>doesn&amp;rsquo;t want kids</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>pisces</td>\n",
       "      <td>no</td>\n",
       "      <td>english, german (poorly)</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>athletic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>graduated from college/university</td>\n",
       "      <td>hey how's it going? currently vague on the pro...</td>\n",
       "      <td>work work work work + play</td>\n",
       "      <td>creating imagery to look at:&lt;br /&gt;\\nhttp://bag...</td>\n",
       "      <td>i smile a lot and my inquisitive nature</td>\n",
       "      <td>...</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>NaN</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>aquarius</td>\n",
       "      <td>no</td>\n",
       "      <td>english</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age       body_type               diet    drinks      drugs  \\\n",
       "0   22  a little extra  strictly anything  socially      never   \n",
       "1   35         average       mostly other     often  sometimes   \n",
       "2   38            thin           anything  socially        NaN   \n",
       "3   23            thin         vegetarian  socially        NaN   \n",
       "4   29        athletic                NaN  socially      never   \n",
       "\n",
       "                           education  \\\n",
       "0      working on college/university   \n",
       "1              working on space camp   \n",
       "2     graduated from masters program   \n",
       "3      working on college/university   \n",
       "4  graduated from college/university   \n",
       "\n",
       "                                              essay0  \\\n",
       "0  about me:<br />\\n<br />\\ni would love to think...   \n",
       "1  i am a chef: this is what that means.<br />\\n1...   \n",
       "2  i'm not ashamed of much, but writing public te...   \n",
       "3          i work in a library and go to school. . .   \n",
       "4  hey how's it going? currently vague on the pro...   \n",
       "\n",
       "                                              essay1  \\\n",
       "0  currently working as an international agent fo...   \n",
       "1  dedicating everyday to being an unbelievable b...   \n",
       "2  i make nerdy software for musicians, artists, ...   \n",
       "3          reading things written by old dead people   \n",
       "4                         work work work work + play   \n",
       "\n",
       "                                              essay2  \\\n",
       "0  making people laugh.<br />\\nranting about a go...   \n",
       "1  being silly. having ridiculous amonts of fun w...   \n",
       "2  improvising in different contexts. alternating...   \n",
       "3  playing synthesizers and organizing books acco...   \n",
       "4  creating imagery to look at:<br />\\nhttp://bag...   \n",
       "\n",
       "                                              essay3    ...      \\\n",
       "0  the way i look. i am a six foot half asian, ha...    ...       \n",
       "1                                                NaN    ...       \n",
       "2  my large jaw and large glasses are the physica...    ...       \n",
       "3                  socially awkward but i do my best    ...       \n",
       "4            i smile a lot and my inquisitive nature    ...       \n",
       "\n",
       "                          location  \\\n",
       "0  south san francisco, california   \n",
       "1              oakland, california   \n",
       "2        san francisco, california   \n",
       "3             berkeley, california   \n",
       "4        san francisco, california   \n",
       "\n",
       "                                      offspring orientation  \\\n",
       "0  doesn&rsquo;t have kids, but might want them    straight   \n",
       "1  doesn&rsquo;t have kids, but might want them    straight   \n",
       "2                                           NaN    straight   \n",
       "3                       doesn&rsquo;t want kids    straight   \n",
       "4                                           NaN    straight   \n",
       "\n",
       "                        pets                                  religion sex  \\\n",
       "0  likes dogs and likes cats     agnosticism and very serious about it   m   \n",
       "1  likes dogs and likes cats  agnosticism but not too serious about it   m   \n",
       "2                   has cats                                       NaN   m   \n",
       "3                 likes cats                                       NaN   m   \n",
       "4  likes dogs and likes cats                                       NaN   m   \n",
       "\n",
       "                                 sign     smokes  \\\n",
       "0                              gemini  sometimes   \n",
       "1                              cancer         no   \n",
       "2  pisces but it doesn&rsquo;t matter         no   \n",
       "3                              pisces         no   \n",
       "4                            aquarius         no   \n",
       "\n",
       "                                              speaks     status  \n",
       "0                                            english     single  \n",
       "1  english (fluently), spanish (poorly), french (...     single  \n",
       "2                               english, french, c++  available  \n",
       "3                           english, german (poorly)     single  \n",
       "4                                            english     single  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading in raw data\n",
    "df = pd.read_csv('../profiles.csv/profiles.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59946 entries, 0 to 59945\n",
      "Data columns (total 31 columns):\n",
      "age            59946 non-null int64\n",
      "body_type      54650 non-null object\n",
      "diet           35551 non-null object\n",
      "drinks         56961 non-null object\n",
      "drugs          45866 non-null object\n",
      "education      53318 non-null object\n",
      "essay0         54458 non-null object\n",
      "essay1         52374 non-null object\n",
      "essay2         50308 non-null object\n",
      "essay3         48470 non-null object\n",
      "essay4         49409 non-null object\n",
      "essay5         49096 non-null object\n",
      "essay6         46175 non-null object\n",
      "essay7         47495 non-null object\n",
      "essay8         40721 non-null object\n",
      "essay9         47343 non-null object\n",
      "ethnicity      54266 non-null object\n",
      "height         59943 non-null float64\n",
      "income         59946 non-null int64\n",
      "job            51748 non-null object\n",
      "last_online    59946 non-null object\n",
      "location       59946 non-null object\n",
      "offspring      24385 non-null object\n",
      "orientation    59946 non-null object\n",
      "pets           40025 non-null object\n",
      "religion       39720 non-null object\n",
      "sex            59946 non-null object\n",
      "sign           48890 non-null object\n",
      "smokes         54434 non-null object\n",
      "speaks         59896 non-null object\n",
      "status         59946 non-null object\n",
      "dtypes: float64(1), int64(2), object(28)\n",
      "memory usage: 14.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 10 essays and a number of descriptors. The only numerical variables are income, height and age. \n",
    "We also have a large dataset with close to 60,000 entries (59946). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of all of these, in our research question, we only care about the dating profiles of straight, single males. So we filter accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correct subset of data\n",
    "df = df[(df['sex']==\"m\")\n",
    "        &(df['orientation']==\"straight\") \n",
    "        & (df['status']==\"single\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29163, 31)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore data: \n",
    "Dig deeper into the data. Query it, visualize it, and identify relationships among the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify data quality: How clean/dirty is the data? Document any quality issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables of interest are categorical, and therefore not easily imputed. \n",
    "It may be possible to impute missing height. But the remaining categorical values in the data bear no causal relationship with height (other than perhaps, race) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Focus on the chosen variables of importance and the essay\n",
    "must_haves = ['body_type', 'height', 'education', 'ethnicity', 'sex', 'essay0']\n",
    "#drop the rest\n",
    "df = df[must_haves]\n",
    "#drop null values\n",
    "df = df.dropna(subset= must_haves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 29163/29163 [00:12<00:00, 2302.66it/s]\n"
     ]
    }
   ],
   "source": [
    "# Some of the essays have just a link in the text. BeautifulSoup sees that and gets \n",
    "# the wrong idea. This line hides those warnings.\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='bs4')\n",
    "def clean(text):\n",
    "    \"\"\"\n",
    "    Takes in raw text of essays\n",
    "    Removes all null values and url links\n",
    "    \n",
    "    Parameters\n",
    "    ---------\n",
    "    text: string\n",
    "        Usually, this is the raw profile essay \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    t: string\n",
    "        This refers to the cleaned profile essay\n",
    "    \"\"\"\n",
    "    if pd.isnull(text):\n",
    "        t = np.nan\n",
    "    else:\n",
    "        t = BeautifulSoup(text, 'lxml').get_text()\n",
    "        t = t.lower()\n",
    "        t = t.strip().replace('\\n','').replace(\"\\r\", \" \").replace('\\t', '')\n",
    "        bad_words = ['http', 'www', '\\nnan']\n",
    "\n",
    "        for b in bad_words:\n",
    "            t = t.replace(b, '')\n",
    "    #After these subsitutions, the string may become empty\n",
    "    if t == '':\n",
    "        t = np.nan\n",
    "    \n",
    "    return t\n",
    "\n",
    "#Clearing out all HTML and unnecessary characters\n",
    "df['essay0'] = df['essay0'].progress_apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20576, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATING NEW COLUMNS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of the sections here are taken directly from the following link, with specific modifications\n",
    "Taken directly from:\n",
    "https://github.com/UM-CSS/CSSLabs-NLP/blob/master/1_Data_munging.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recode(text, dictionary, default=np.nan):\n",
    "    \"\"\"\n",
    "    Function for recoding categories in a column based on exact matches\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    text: a string\n",
    "    \n",
    "    dictionary: dictionary\n",
    "        contains desired values as keys, and all the\n",
    "        labels to be matched with it used as values\n",
    "    \n",
    "    default: string or None\n",
    "        the value to be used if no match is found with the \n",
    "        dictionary keys\n",
    "    \n",
    "    Returns\n",
    "    ------\n",
    "    out: a string or None\n",
    "    \n",
    "    \"\"\"\n",
    "    out = default\n",
    "    text = str(text)\n",
    "    \n",
    "    for x in dictionary.keys():\n",
    "        for y in dictionary[x]:\n",
    "            if y == text: #exact match\n",
    "                out = x\n",
    "                return out\n",
    "    return out\n",
    "\n",
    "#Might be possible to refactor this function out completely\n",
    "def recode_fuzzy(text, dictionary, default=np.nan):\n",
    "    \"\"\"\n",
    "    Function for recoding categories in a column based on partial matches\n",
    "    \n",
    "    text: a string\n",
    "    \n",
    "    dictionary: dictionary\n",
    "        contains desired values as keys, and all the\n",
    "        labels to be matched with it used as values\n",
    "    \n",
    "    default: string or None\n",
    "        the value to be used if no match is found with the \n",
    "        dictionary keys\n",
    "        \n",
    "    Returns\n",
    "    ------\n",
    "    out: a string or None\n",
    "\n",
    "    \"\"\"\n",
    "    out = default\n",
    "    text = str(text)\n",
    "    \n",
    "    for x in dictionary.keys():\n",
    "        for y in dictionary[x]:\n",
    "            if y in text: #partial match\n",
    "                out = x\n",
    "                return out\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tese dictionaries were created from all the observed unique values\n",
    "\n",
    "#Education\n",
    "ed_levels = {'High School or less': ['dropped out of high school', 'working on high school','graduated from high school', 'working on college/university', \n",
    "                    'two-year college', 'dropped out of college/university', \n",
    "                    'high school'], \n",
    "             'More than High School': ['graduated from college/university', \n",
    "                    'working on masters program', 'working on ph.d program', \n",
    "                    'college/university', 'working on law school', \n",
    "                    'dropped out of masters program', \n",
    "                    'dropped out of ph.d program', 'dropped out of law school', \n",
    "                    'dropped out of med school',\n",
    "                    'graduated from masters program',\n",
    "                    'graduated from ph.d program',                           \n",
    "                    'graduated from law school', \n",
    "                    'graduated from med school', 'masters program', \n",
    "                    'ph.d program', 'law school', 'med school']}\n",
    "\n",
    "#body type\n",
    "bodies = {'fit': ['fit', 'athletic', 'jacked'], \n",
    "          'not_fit': ['average', 'thin', 'skinny','curvey', 'a little extra', \n",
    "                      'full figured', 'overweight', 'rather not say', 'used up']\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['edu'] = df.education.apply(recode, dictionary=ed_levels, \n",
    "                                            default='unknown')\n",
    "df['fit'] = df.body_type.apply(recode, dictionary=bodies, \n",
    "                                            default='unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# race/ethnicity for exact matching\n",
    "ethn = {'White': ['white', 'middle eastern', 'middle eastern, white'], \n",
    "        'Asian': ['asian', 'indian', 'asian, pacific islander'], \n",
    "        'Black': ['black']\n",
    "       }   \n",
    "\n",
    "# race/ethnicityfor fuzzy matching\n",
    "ethn2 = {'Latinx': ['latin'], \n",
    "         'multiple': [','], \n",
    "         np.nan: ['nan']\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def census_2010_ethnicity(t):\n",
    "    '''\n",
    "    recodes ethnicity variables according to census categories\n",
    "    This conversion happens through dictionaries declared in the\n",
    "    previous cell. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    t- string\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    e- string\n",
    "    '''\n",
    "    text = str(t)\n",
    "    e = recode(text, ethn, default='other')\n",
    "    if 'other' == e:\n",
    "        e = recode_fuzzy(text, ethn2, default='other')\n",
    "    return e\n",
    "\n",
    "df['race_ethnicity'] = df.ethnicity.apply(census_2010_ethnicity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#there may be some way to build in the calculation of the first quartile\n",
    "def height_check(inches):\n",
    "    \"\"\"\n",
    "    takes in height and returns a label of short or not short\n",
    "    uses the first quartile as the cutoff for not being short\n",
    "    \n",
    "    parameters\n",
    "    ----------\n",
    "    inches: float\n",
    "        The height of the user in inches\n",
    "    \n",
    "    returns\n",
    "    ------\n",
    "    h: string\n",
    "        A label- 'short' or 'not short'\n",
    "    \n",
    "    \"\"\"\n",
    "    h = 'not_short'\n",
    "    if inches <= 69:\n",
    "        #This number was extracted as the first quartile of the distribution of height\n",
    "        h = 'short'\n",
    "    return h\n",
    "df['height'] = pd.to_numeric(df['height'])\n",
    "df['height_group'] = df.height.apply(height_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now drop the original variables\n",
    "df.drop(columns=['body_type', 'ethnicity','height','education'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('profiles_filtered.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROFILE LENGTH AND VARIABLES OF INTEREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By Ethnicity\n",
    "sns_race_plot = sns.boxplot(x=\"race_ethnicity\", y=\"profile_length\", data=df)\n",
    "sns_race_plot.set(title = 'Racial Background and Length of Dating Profile', \n",
    "                  xlabel = 'Race', ylabel = 'Number of Words')\n",
    "sns_race_plot.figure.savefig('profile_race.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By Education \n",
    "sns_plot = sns.boxplot(x=\"edu\", y=\"profile_length\", data=df)\n",
    "sns_plot.set(title = 'Education and Length of Dating Profile', \n",
    "                                                           xlabel = 'Education', \n",
    "                                                           ylabel = 'Number of Words' )\n",
    "sns_plot.figure.savefig('profile_educ.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By Height \n",
    "sns_plot = sns.boxplot(x=\"height_group, y=\"profile_length\", data=df)\n",
    "sns_plot.set(title = 'Height and Length of Dating Profile', \n",
    "                                                           xlabel = 'Height', \n",
    "                                                           ylabel = 'Number of Words' )\n",
    "sns_plot.figure.savefig('profile_height.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By Ditness Level\n",
    "sns_plot = sns.boxplot(x=\"fit, y=\"profile_length\", data=df)\n",
    "sns_plot.set(title = 'Fitness and Length of Dating Profile', \n",
    "                                                           xlabel = 'Height', \n",
    "                                                           ylabel = 'Number of Words' )\n",
    "sns_plot.figure.savefig('profile_fitness.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEXT EDITING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 20576/20576 [79:41:19<00:00, 10.85s/it]"
     ]
    }
   ],
   "source": [
    "# First, fix conjoined words in the essay\n",
    "# This may take up to 10 minutes\n",
    "df['essay0'] = df['essay0'].progress_apply(split_incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['long_words'] = df['essay0'].progress_apply(get_npoly)\n",
    "df['flesch'] = df['essay0'].progress_apply(get_flesch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this will the main data file for the rest of the analysis\n",
    "df.to_csv('compressed_okcupid.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
