{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Filter\n",
    "### The purpose of this notebook is four-fold:\n",
    "1) Filter data to only the relevant rows\n",
    "\n",
    "2) Delete the unnecessary columns\n",
    "\n",
    "3) Suitably edit the text to allow for topic modeling\n",
    "\n",
    "4) Create new variables to assist with demographic comparisons of topics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# For Data Cleaning\n",
    "from bs4 import BeautifulSoup\n",
    "from split_utils import *\n",
    "from text_complexity_utils import get_npoly, get_flesch\n",
    "\n",
    "#General Imports\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correct subset of data\n",
    "df = pd.read_csv('../profiles.csv/profiles.csv')\n",
    "df = df[(df['sex']==\"m\")\n",
    "        &(df['orientation']==\"straight\") \n",
    "        & (df['status']==\"single\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29163, 31)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 29163/29163 [00:12<00:00, 2302.66it/s]\n"
     ]
    }
   ],
   "source": [
    "# Some of the essays have just a link in the text. BeautifulSoup sees that and gets \n",
    "# the wrong idea. This line hides those warnings.\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='bs4')\n",
    "def clean(text):\n",
    "    \"\"\"\n",
    "    Removes all null values\n",
    "    \"\"\"\n",
    "    if pd.isnull(text):\n",
    "        t = np.nan\n",
    "    else:\n",
    "        t = BeautifulSoup(text, 'lxml').get_text()\n",
    "        t = t.lower()\n",
    "        t = t.strip().replace('\\n','').replace(\"\\r\", \" \").replace('\\t', '')\n",
    "        bad_words = ['http', 'www', '\\nnan']\n",
    "\n",
    "        for b in bad_words:\n",
    "            t = t.replace(b, '')\n",
    "    if t == '':\n",
    "        t = np.nan\n",
    "    \n",
    "    return t\n",
    "\n",
    "#Clearing out all HTML and unnecessary characters\n",
    "df['essay0'] = df['essay0'].progress_apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "must_haves = ['body_type', 'height', 'education', 'ethnicity', 'sex', 'essay0']\n",
    "df = df.dropna(subset= must_haves)\n",
    "df = df.drop(columns=['essay1', 'essay2', 'essay3','essay4','essay5','essay6','essay7',\n",
    "                      'essay8', 'essay9', 'income','job','last_online','location','offspring',\n",
    "                      'orientation','pets','religion','sex','sign','smokes','speaks','status',\n",
    "                      'diet', 'drinks', 'drugs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20576, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix Conjoined Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATING NEW COLUMNS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of the sections here are taken directly from the following link, with specific modifications\n",
    "Taken directly from:\n",
    "https://github.com/UM-CSS/CSSLabs-NLP/blob/master/1_Data_munging.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recode(text, dictionary, default=np.nan):\n",
    "    '''Function for recoding categories in a column based on exact matches'''\n",
    "    out = default\n",
    "    text = str(text)\n",
    "    \n",
    "    for x in dictionary.keys():\n",
    "        for y in dictionary[x]:\n",
    "            if y == text: #exact match\n",
    "                out = x\n",
    "                return out\n",
    "    return out\n",
    "\n",
    "def recode_fuzzy(text, dictionary, default=np.nan):\n",
    "    '''Function for recoding categories in a column based on partial matches'''\n",
    "    out = default\n",
    "    text = str(text)\n",
    "    \n",
    "    for x in dictionary.keys():\n",
    "        for y in dictionary[x]:\n",
    "            if y in text: #partial match\n",
    "                out = x\n",
    "                return out\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ed_levels = {'High School or less': ['dropped out of high school', 'working on high school','graduated from high school', 'working on college/university', \n",
    "                    'two-year college', 'dropped out of college/university', \n",
    "                    'high school'], \n",
    "             'More than High School': ['graduated from college/university', \n",
    "                    'working on masters program', 'working on ph.d program', \n",
    "                    'college/university', 'working on law school', \n",
    "                    'dropped out of masters program', \n",
    "                    'dropped out of ph.d program', 'dropped out of law school', \n",
    "                    'dropped out of med school',\n",
    "                    'graduated from masters program',\n",
    "                    'graduated from ph.d program',                           \n",
    "                    'graduated from law school', \n",
    "                    'graduated from med school', 'masters program', \n",
    "                    'ph.d program', 'law school', 'med school']}\n",
    "\n",
    "#body type\n",
    "bodies = {'fit': ['fit', 'athletic', 'jacked'], \n",
    "          'not_fit': ['average', 'thin', 'skinny','curvey', 'a little extra', \n",
    "                      'full figured', 'overweight', 'rather not say', 'used up']\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['edu'] = df.education.apply(recode, dictionary=ed_levels, \n",
    "                                            default='unknown')\n",
    "df['fit'] = df.body_type.apply(recode, dictionary=bodies, \n",
    "                                            default='unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# race/ethnicity for exact matching\n",
    "ethn = {'White': ['white', 'middle eastern', 'middle eastern, white'], \n",
    "        'Asian': ['asian', 'indian', 'asian, pacific islander'], \n",
    "        'Black': ['black']       }   \n",
    "\n",
    "# race/ethnicityfor fuzzy matching\n",
    "ethn2 = {'Latinx': ['latin'], 'multiple': [','], np.nan: ['nan']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def census_2010_ethnicity(t):\n",
    "    text = str(t)\n",
    "    e = recode(text, ethn, default='other')\n",
    "    if 'other' == e:\n",
    "        e = recode_fuzzy(text, ethn2, default='other')\n",
    "    return e\n",
    "\n",
    "df['race_ethnicity'] = df.ethnicity.apply(census_2010_ethnicity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def height_check(inches):\n",
    "    h = 'not_short'\n",
    "    if inches <= 69:\n",
    "        h = 'short'\n",
    "    return h\n",
    "df['height'] = pd.to_numeric(df['height'])\n",
    "df['height_group'] = df.height.apply(height_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now drop the original variables\n",
    "df.drop(columns=['body_type', 'ethnicity','height','education'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('profiles_filtered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20576, 6)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEXT EDITING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▉                                                                        | 272/20576 [1:07:23<99:14:37, 17.60s/it]"
     ]
    }
   ],
   "source": [
    "# First, fix conjoined words in the essay\n",
    "# This may take up to 10 minutes\n",
    "df['essay0'] = df['essay0'].progress_apply(split_incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['long_words'] = df['essay0'].progress_apply(get_npoly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['flesch'] = df['essay0'].progress_apply(get_flesch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('compressed_okcupid.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
