{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Filter\n",
    "We are going to apply the CRISP-DM Framework for Data Analysis here (as outlined here: https://www.datascience-pm.com/crisp-dm-2/)\n",
    "This notebook deals with the first three steps Business Understanding, Data Understanding and Data Preparation. The remaining two components can be found in the Doc2Vec Jupyter Notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Business understanding â€“ What does the business need?*\n",
    "The business, in this case, is OkCupid, and it might be facing a large number of men dropping out of the system because of high competition and limited responses. We cannot confirm this directly with OkCupid, but we do know that self-representation through online dating is a relatively new skill to gain in our species' long and checkered history. So why not provide some guidance along the way? \n",
    "\n",
    "The goal would be to provide data-driven guidance to male users of the service so that they stand out from the competition and get matched more often. This will increase the rating of the app, and lead to more sign-ups and revenue. \n",
    "\n",
    "Getting present-day data would be challenging. Many researchers have gained access to profiles and conversation data, but usually have the funding support and credentials of their universities to back them. Moreover, online dating data involves considerable privacy concerns. In such a situation, it would be best to acquire a low-cost data set that anonymizes data, but need not include all aspects of profiles or even be up-to-date. \n",
    "\n",
    "Success for us would involve first testing for the extent of homogeneity in dating profiles, and then providing support with helpful UX features that provide tips to remove that homeogeneity and sound memorable vis-a-vis other users. In technical terms, this means identifying from text the most common topics, language patterns and keywords, and then providing guidance to prevent such repetition. It would also be useful to check if these patterns vary in different subgroups of users, as indicated by variables like height, weight/fitness level, race and education level. \n",
    "\n",
    "Given these objectives, we will be proceeding with using Python and R (depending on which of them contains the most suitable packages for our specific and evolving tasks)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding\n",
    "    \n",
    "- Collect initial data: Acquire the necessary data and (if necessary) load it into your analysis tool.\n",
    "- Describe data: Examine the data and document its surface properties like data format, number of records, or field identities.\n",
    "- Explore data: Dig deeper into the data. Query it, visualize it, and identify relationships among the data.\n",
    "- Verify data quality: How clean/dirty is the data? Document any quality issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Collect Initial Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "# For Data Cleaning\n",
    "from bs4 import BeautifulSoup\n",
    "from split_utils import *\n",
    "#from text_complexity_utils import get_npoly, get_flesch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>body_type</th>\n",
       "      <th>diet</th>\n",
       "      <th>drinks</th>\n",
       "      <th>drugs</th>\n",
       "      <th>education</th>\n",
       "      <th>essay0</th>\n",
       "      <th>essay1</th>\n",
       "      <th>essay2</th>\n",
       "      <th>essay3</th>\n",
       "      <th>...</th>\n",
       "      <th>location</th>\n",
       "      <th>offspring</th>\n",
       "      <th>orientation</th>\n",
       "      <th>pets</th>\n",
       "      <th>religion</th>\n",
       "      <th>sex</th>\n",
       "      <th>sign</th>\n",
       "      <th>smokes</th>\n",
       "      <th>speaks</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>a little extra</td>\n",
       "      <td>strictly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>about me:&lt;br /&gt;\\n&lt;br /&gt;\\ni would love to think...</td>\n",
       "      <td>currently working as an international agent fo...</td>\n",
       "      <td>making people laugh.&lt;br /&gt;\\nranting about a go...</td>\n",
       "      <td>the way i look. i am a six foot half asian, ha...</td>\n",
       "      <td>...</td>\n",
       "      <td>south san francisco, california</td>\n",
       "      <td>doesn&amp;rsquo;t have kids, but might want them</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism and very serious about it</td>\n",
       "      <td>m</td>\n",
       "      <td>gemini</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>english</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>average</td>\n",
       "      <td>mostly other</td>\n",
       "      <td>often</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>working on space camp</td>\n",
       "      <td>i am a chef: this is what that means.&lt;br /&gt;\\n1...</td>\n",
       "      <td>dedicating everyday to being an unbelievable b...</td>\n",
       "      <td>being silly. having ridiculous amonts of fun w...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>oakland, california</td>\n",
       "      <td>doesn&amp;rsquo;t have kids, but might want them</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>agnosticism but not too serious about it</td>\n",
       "      <td>m</td>\n",
       "      <td>cancer</td>\n",
       "      <td>no</td>\n",
       "      <td>english (fluently), spanish (poorly), french (...</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>thin</td>\n",
       "      <td>anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>graduated from masters program</td>\n",
       "      <td>i'm not ashamed of much, but writing public te...</td>\n",
       "      <td>i make nerdy software for musicians, artists, ...</td>\n",
       "      <td>improvising in different contexts. alternating...</td>\n",
       "      <td>my large jaw and large glasses are the physica...</td>\n",
       "      <td>...</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>NaN</td>\n",
       "      <td>straight</td>\n",
       "      <td>has cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>pisces but it doesn&amp;rsquo;t matter</td>\n",
       "      <td>no</td>\n",
       "      <td>english, french, c++</td>\n",
       "      <td>available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>thin</td>\n",
       "      <td>vegetarian</td>\n",
       "      <td>socially</td>\n",
       "      <td>NaN</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>i work in a library and go to school. . .</td>\n",
       "      <td>reading things written by old dead people</td>\n",
       "      <td>playing synthesizers and organizing books acco...</td>\n",
       "      <td>socially awkward but i do my best</td>\n",
       "      <td>...</td>\n",
       "      <td>berkeley, california</td>\n",
       "      <td>doesn&amp;rsquo;t want kids</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>pisces</td>\n",
       "      <td>no</td>\n",
       "      <td>english, german (poorly)</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29</td>\n",
       "      <td>athletic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>graduated from college/university</td>\n",
       "      <td>hey how's it going? currently vague on the pro...</td>\n",
       "      <td>work work work work + play</td>\n",
       "      <td>creating imagery to look at:&lt;br /&gt;\\nhttp://bag...</td>\n",
       "      <td>i smile a lot and my inquisitive nature</td>\n",
       "      <td>...</td>\n",
       "      <td>san francisco, california</td>\n",
       "      <td>NaN</td>\n",
       "      <td>straight</td>\n",
       "      <td>likes dogs and likes cats</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>aquarius</td>\n",
       "      <td>no</td>\n",
       "      <td>english</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age       body_type               diet    drinks      drugs  \\\n",
       "0   22  a little extra  strictly anything  socially      never   \n",
       "1   35         average       mostly other     often  sometimes   \n",
       "2   38            thin           anything  socially        NaN   \n",
       "3   23            thin         vegetarian  socially        NaN   \n",
       "4   29        athletic                NaN  socially      never   \n",
       "\n",
       "                           education  \\\n",
       "0      working on college/university   \n",
       "1              working on space camp   \n",
       "2     graduated from masters program   \n",
       "3      working on college/university   \n",
       "4  graduated from college/university   \n",
       "\n",
       "                                              essay0  \\\n",
       "0  about me:<br />\\n<br />\\ni would love to think...   \n",
       "1  i am a chef: this is what that means.<br />\\n1...   \n",
       "2  i'm not ashamed of much, but writing public te...   \n",
       "3          i work in a library and go to school. . .   \n",
       "4  hey how's it going? currently vague on the pro...   \n",
       "\n",
       "                                              essay1  \\\n",
       "0  currently working as an international agent fo...   \n",
       "1  dedicating everyday to being an unbelievable b...   \n",
       "2  i make nerdy software for musicians, artists, ...   \n",
       "3          reading things written by old dead people   \n",
       "4                         work work work work + play   \n",
       "\n",
       "                                              essay2  \\\n",
       "0  making people laugh.<br />\\nranting about a go...   \n",
       "1  being silly. having ridiculous amonts of fun w...   \n",
       "2  improvising in different contexts. alternating...   \n",
       "3  playing synthesizers and organizing books acco...   \n",
       "4  creating imagery to look at:<br />\\nhttp://bag...   \n",
       "\n",
       "                                              essay3  ...  \\\n",
       "0  the way i look. i am a six foot half asian, ha...  ...   \n",
       "1                                                NaN  ...   \n",
       "2  my large jaw and large glasses are the physica...  ...   \n",
       "3                  socially awkward but i do my best  ...   \n",
       "4            i smile a lot and my inquisitive nature  ...   \n",
       "\n",
       "                          location  \\\n",
       "0  south san francisco, california   \n",
       "1              oakland, california   \n",
       "2        san francisco, california   \n",
       "3             berkeley, california   \n",
       "4        san francisco, california   \n",
       "\n",
       "                                      offspring orientation  \\\n",
       "0  doesn&rsquo;t have kids, but might want them    straight   \n",
       "1  doesn&rsquo;t have kids, but might want them    straight   \n",
       "2                                           NaN    straight   \n",
       "3                       doesn&rsquo;t want kids    straight   \n",
       "4                                           NaN    straight   \n",
       "\n",
       "                        pets                                  religion sex  \\\n",
       "0  likes dogs and likes cats     agnosticism and very serious about it   m   \n",
       "1  likes dogs and likes cats  agnosticism but not too serious about it   m   \n",
       "2                   has cats                                       NaN   m   \n",
       "3                 likes cats                                       NaN   m   \n",
       "4  likes dogs and likes cats                                       NaN   m   \n",
       "\n",
       "                                 sign     smokes  \\\n",
       "0                              gemini  sometimes   \n",
       "1                              cancer         no   \n",
       "2  pisces but it doesn&rsquo;t matter         no   \n",
       "3                              pisces         no   \n",
       "4                            aquarius         no   \n",
       "\n",
       "                                              speaks     status  \n",
       "0                                            english     single  \n",
       "1  english (fluently), spanish (poorly), french (...     single  \n",
       "2                               english, french, c++  available  \n",
       "3                           english, german (poorly)     single  \n",
       "4                                            english     single  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading in raw data\n",
    "df = pd.read_csv('../profiles.csv/profiles.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Describe data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59946, 31)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59946 entries, 0 to 59945\n",
      "Data columns (total 31 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   age          59946 non-null  int64  \n",
      " 1   body_type    54650 non-null  object \n",
      " 2   diet         35551 non-null  object \n",
      " 3   drinks       56961 non-null  object \n",
      " 4   drugs        45866 non-null  object \n",
      " 5   education    53318 non-null  object \n",
      " 6   essay0       54458 non-null  object \n",
      " 7   essay1       52374 non-null  object \n",
      " 8   essay2       50308 non-null  object \n",
      " 9   essay3       48470 non-null  object \n",
      " 10  essay4       49409 non-null  object \n",
      " 11  essay5       49096 non-null  object \n",
      " 12  essay6       46175 non-null  object \n",
      " 13  essay7       47495 non-null  object \n",
      " 14  essay8       40721 non-null  object \n",
      " 15  essay9       47343 non-null  object \n",
      " 16  ethnicity    54266 non-null  object \n",
      " 17  height       59943 non-null  float64\n",
      " 18  income       59946 non-null  int64  \n",
      " 19  job          51748 non-null  object \n",
      " 20  last_online  59946 non-null  object \n",
      " 21  location     59946 non-null  object \n",
      " 22  offspring    24385 non-null  object \n",
      " 23  orientation  59946 non-null  object \n",
      " 24  pets         40025 non-null  object \n",
      " 25  religion     39720 non-null  object \n",
      " 26  sex          59946 non-null  object \n",
      " 27  sign         48890 non-null  object \n",
      " 28  smokes       54434 non-null  object \n",
      " 29  speaks       59896 non-null  object \n",
      " 30  status       59946 non-null  object \n",
      "dtypes: float64(1), int64(2), object(28)\n",
      "memory usage: 7.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>height</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>59946.000000</td>\n",
       "      <td>59943.000000</td>\n",
       "      <td>59946.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>32.340290</td>\n",
       "      <td>68.295281</td>\n",
       "      <td>20033.222534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.452779</td>\n",
       "      <td>3.994803</td>\n",
       "      <td>97346.192104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>37.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>110.000000</td>\n",
       "      <td>95.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                age        height          income\n",
       "count  59946.000000  59943.000000    59946.000000\n",
       "mean      32.340290     68.295281    20033.222534\n",
       "std        9.452779      3.994803    97346.192104\n",
       "min       18.000000      1.000000       -1.000000\n",
       "25%       26.000000     66.000000       -1.000000\n",
       "50%       30.000000     68.000000       -1.000000\n",
       "75%       37.000000     71.000000       -1.000000\n",
       "max      110.000000     95.000000  1000000.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 10 essays and a number of descriptors. The only numerical variables are income, height and age. \n",
    "We also have a large dataset with close to 60,000 entries (59946). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Explore Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With mostly categorical data, the suite of available methods for exploratory data analysis is somewhat limited. Here, I am including a treemap plot generated in R "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Treemap of OkCupid Dating Profiles Data](full_treemap.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also detect interesting relationships across cross-tabulations of categorical variables. Here again, I have included cross-tabulations from R plots for Ethnicity and Gender against the remaining variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Treemap of OkCupid Data by Gender](img/by_gender.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Treemap of OkCupid Data by Ethnicity](ethnicity_treemap.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Verify Data Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are concerned with quality along two dimensions. \n",
    "- Extent of missing values. \n",
    "- Reliability of text data (free of spelling errors, URLS and any unncessary characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age            0.000000\n",
       "body_type      0.088346\n",
       "diet           0.406950\n",
       "drinks         0.049795\n",
       "drugs          0.234878\n",
       "education      0.110566\n",
       "essay0         0.091549\n",
       "essay1         0.126314\n",
       "essay2         0.160778\n",
       "essay3         0.191439\n",
       "essay4         0.175775\n",
       "essay5         0.180996\n",
       "essay6         0.229723\n",
       "essay7         0.207704\n",
       "essay8         0.320705\n",
       "essay9         0.210239\n",
       "ethnicity      0.094752\n",
       "height         0.000050\n",
       "income         0.000000\n",
       "job            0.136756\n",
       "last_online    0.000000\n",
       "location       0.000000\n",
       "offspring      0.593217\n",
       "orientation    0.000000\n",
       "pets           0.332316\n",
       "religion       0.337404\n",
       "sex            0.000000\n",
       "sign           0.184433\n",
       "smokes         0.091949\n",
       "speaks         0.000834\n",
       "status         0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "**Data Preparation â€“ How do we organize the data for modeling?**\n",
    "\n",
    "Fortunately, this is our sole dataset and does not seem to require any form of integration\n",
    "\n",
    "**Select Data: Determine which data sets will be used and document reasons for inclusion/exclusion.**\n",
    "   We would need data on OkCupid users, but without violating user privacy. We therefore leverage the anonymized and open dataset from 2012 (linked in README.md). With our focus on single male heterosexual users, we are able to filter this original dataset down from about 60,000 users (men and women) to only about 20,000. \n",
    "   \n",
    "**Clean Data**   \n",
    "The focus of our cleaning will be on the core  dating profiles themselves, with common mis-spellings and conjoined words. \n",
    "We will also 'shrink' the large number of categories for variables such as fitness and ethnicity, to save on degrees of freedom. \n",
    "    \n",
    "**Construct data**: \n",
    "One key aspect of this research exercise is aspects of language and data use. These are not presenting the data to begin with. We will leverage Spacy for this purpose to generate readability metrics like the Flesch-Kincaid index. \n",
    "We will also create a variable to classify heights, since our focus on topic models fits better with categorical rather than continuous outcomes. \n",
    "\n",
    "**Integrate data:**\n",
    "Fortunately, in this instance, this dataset itself is sufficient for addressing our research questions. The anonymized nature of the data (with no ID or identifying variable) would have made integration challenging. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of all of these, in our research question, we only care about the dating profiles of straight, single males. So we filter accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correct subset of data\n",
    "df = df[(df['sex']==\"m\")\n",
    "        &(df['orientation']==\"straight\") \n",
    "        & (df['status']==\"single\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29163, 31)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore data: \n",
    "Dig deeper into the data. Query it, visualize it, and identify relationships among the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify data quality: How clean/dirty is the data? Document any quality issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputation Decision\n",
    "The variables of interest are categorical, and therefore not easily imputed. \n",
    "It may be possible to impute missing height. But the remaining categorical values in the data bear no causal relationship with height (other than perhaps, race)\n",
    "In any case, we just saw the percentage of missing data for height is negligible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Focus on the chosen variables of importance and the essay\n",
    "must_haves = ['body_type', 'height', 'education', 'ethnicity', 'sex', 'essay0']\n",
    "#drop the rest\n",
    "df = df[must_haves]\n",
    "#drop null values\n",
    "df = df.dropna(subset= must_haves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 29163/29163 [00:12<00:00, 2302.66it/s]\n"
     ]
    }
   ],
   "source": [
    "# Some of the essays have just a link in the text. BeautifulSoup sees that and gets \n",
    "# the wrong idea. This line hides those warnings.\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='bs4')\n",
    "def clean(text):\n",
    "    \"\"\"\n",
    "    Takes in raw text of essays\n",
    "    Removes all null values and url links\n",
    "    \n",
    "    Parameters\n",
    "    ---------\n",
    "    text: string\n",
    "        Usually, this is the raw profile essay \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    t: string\n",
    "        This refers to the cleaned profile essay\n",
    "    \"\"\"\n",
    "    if pd.isnull(text):\n",
    "        t = np.nan\n",
    "    else:\n",
    "        t = BeautifulSoup(text, 'lxml').get_text()\n",
    "        t = t.lower()\n",
    "        t = t.strip().replace('\\n','').replace(\"\\r\", \" \").replace('\\t', '')\n",
    "        bad_words = ['http', 'www', '\\nnan']\n",
    "\n",
    "        for b in bad_words:\n",
    "            t = t.replace(b, '')\n",
    "    #After these subsitutions, the string may become empty\n",
    "    if t == '':\n",
    "        t = np.nan\n",
    "    \n",
    "    return t\n",
    "\n",
    "#Clearing out all HTML and unnecessary characters\n",
    "df['essay0'] = df['essay0'].progress_apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20576, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATING NEW COLUMNS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of the sections here are taken directly from the following link, with specific modifications\n",
    "Taken directly from:\n",
    "https://github.com/UM-CSS/CSSLabs-NLP/blob/master/1_Data_munging.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recode(text, dictionary, default=np.nan):\n",
    "    \"\"\"\n",
    "    Function for recoding categories in a column based on exact matches\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    text: a string\n",
    "    \n",
    "    dictionary: dictionary\n",
    "        contains desired values as keys, and all the\n",
    "        labels to be matched with it used as values\n",
    "    \n",
    "    default: string or None\n",
    "        the value to be used if no match is found with the \n",
    "        dictionary keys\n",
    "    \n",
    "    Returns\n",
    "    ------\n",
    "    out: a string or None\n",
    "    \n",
    "    \"\"\"\n",
    "    out = default\n",
    "    text = str(text)\n",
    "    \n",
    "    for x in dictionary.keys():\n",
    "        for y in dictionary[x]:\n",
    "            if y == text: #exact match\n",
    "                out = x\n",
    "                return out\n",
    "    return out\n",
    "\n",
    "#Might be possible to refactor this function out completely\n",
    "def recode_fuzzy(text, dictionary, default=np.nan):\n",
    "    \"\"\"\n",
    "    Function for recoding categories in a column based on partial matches\n",
    "    \n",
    "    text: a string\n",
    "    \n",
    "    dictionary: dictionary\n",
    "        contains desired values as keys, and all the\n",
    "        labels to be matched with it used as values\n",
    "    \n",
    "    default: string or None\n",
    "        the value to be used if no match is found with the \n",
    "        dictionary keys\n",
    "        \n",
    "    Returns\n",
    "    ------\n",
    "    out: a string or None\n",
    "\n",
    "    \"\"\"\n",
    "    out = default\n",
    "    text = str(text)\n",
    "    \n",
    "    for x in dictionary.keys():\n",
    "        for y in dictionary[x]:\n",
    "            if y in text: #partial match\n",
    "                out = x\n",
    "                return out\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tese dictionaries were created from all the observed unique values\n",
    "\n",
    "#Education\n",
    "ed_levels = {'High School or less': ['dropped out of high school', 'working on high school','graduated from high school', 'working on college/university', \n",
    "                    'two-year college', 'dropped out of college/university', \n",
    "                    'high school'], \n",
    "             'More than High School': ['graduated from college/university', \n",
    "                    'working on masters program', 'working on ph.d program', \n",
    "                    'college/university', 'working on law school', \n",
    "                    'dropped out of masters program', \n",
    "                    'dropped out of ph.d program', 'dropped out of law school', \n",
    "                    'dropped out of med school',\n",
    "                    'graduated from masters program',\n",
    "                    'graduated from ph.d program',                           \n",
    "                    'graduated from law school', \n",
    "                    'graduated from med school', 'masters program', \n",
    "                    'ph.d program', 'law school', 'med school']}\n",
    "\n",
    "#body type\n",
    "bodies = {'fit': ['fit', 'athletic', 'jacked'], \n",
    "          'not_fit': ['average', 'thin', 'skinny','curvey', 'a little extra', \n",
    "                      'full figured', 'overweight', 'rather not say', 'used up']\n",
    "         }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['edu'] = df.education.apply(recode, dictionary=ed_levels, \n",
    "                                            default='unknown')\n",
    "df['fit'] = df.body_type.apply(recode, dictionary=bodies, \n",
    "                                            default='unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# race/ethnicity for exact matching\n",
    "ethn = {'White': ['white', 'middle eastern', 'middle eastern, white'], \n",
    "        'Asian': ['asian', 'indian', 'asian, pacific islander'], \n",
    "        'Black': ['black']\n",
    "       }   \n",
    "\n",
    "# race/ethnicityfor fuzzy matching\n",
    "ethn2 = {'Latinx': ['latin'], \n",
    "         'multiple': [','], \n",
    "         np.nan: ['nan']\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def census_2010_ethnicity(t):\n",
    "    '''\n",
    "    recodes ethnicity variables according to census categories\n",
    "    This conversion happens through dictionaries declared in the\n",
    "    previous cell. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    t- string\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    e- string\n",
    "    '''\n",
    "    text = str(t)\n",
    "    e = recode(text, ethn, default='other')\n",
    "    if 'other' == e:\n",
    "        e = recode_fuzzy(text, ethn2, default='other')\n",
    "    return e\n",
    "\n",
    "df['race_ethnicity'] = df.ethnicity.apply(census_2010_ethnicity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#there may be some way to build in the calculation of the first quartile\n",
    "def height_check(inches):\n",
    "    \"\"\"\n",
    "    takes in height and returns a label of short or not short\n",
    "    uses the first quartile as the cutoff for not being short\n",
    "    \n",
    "    parameters\n",
    "    ----------\n",
    "    inches: float\n",
    "        The height of the user in inches\n",
    "    \n",
    "    returns\n",
    "    ------\n",
    "    h: string\n",
    "        A label- 'short' or 'not short'\n",
    "    \n",
    "    \"\"\"\n",
    "    h = 'not_short'\n",
    "    if inches <= 69:\n",
    "        #This number was extracted as the first quartile of the distribution of height\n",
    "        h = 'short'\n",
    "    return h\n",
    "df['height'] = pd.to_numeric(df['height'])\n",
    "df['height_group'] = df.height.apply(height_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now drop the original variables\n",
    "df.drop(columns=['body_type', 'ethnicity','height','education'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('profiles_filtered.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROFILE LENGTH AND VARIABLES OF INTEREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By Ethnicity\n",
    "sns_race_plot = sns.boxplot(x=\"race_ethnicity\", y=\"profile_length\", data=df)\n",
    "sns_race_plot.set(title = 'Racial Background and Length of Dating Profile', \n",
    "                  xlabel = 'Race', ylabel = 'Number of Words')\n",
    "sns_race_plot.figure.savefig('profile_race.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By Education \n",
    "sns_plot = sns.boxplot(x=\"edu\", y=\"profile_length\", data=df)\n",
    "sns_plot.set(title = 'Education and Length of Dating Profile', \n",
    "                                                           xlabel = 'Education', \n",
    "                                                           ylabel = 'Number of Words' )\n",
    "sns_plot.figure.savefig('profile_educ.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By Height \n",
    "sns_plot = sns.boxplot(x=\"height_group, y=\"profile_length\", data=df)\n",
    "sns_plot.set(title = 'Height and Length of Dating Profile', \n",
    "                                                           xlabel = 'Height', \n",
    "                                                           ylabel = 'Number of Words' )\n",
    "sns_plot.figure.savefig('profile_height.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By Ditness Level\n",
    "sns_plot = sns.boxplot(x=\"fit, y=\"profile_length\", data=df)\n",
    "sns_plot.set(title = 'Fitness and Length of Dating Profile', \n",
    "                                                           xlabel = 'Height', \n",
    "                                                           ylabel = 'Number of Words' )\n",
    "sns_plot.figure.savefig('profile_fitness.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEXT EDITING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20576/20576 [79:41:19<00:00, 10.85s/it]"
     ]
    }
   ],
   "source": [
    "# First, fix conjoined words in the essay\n",
    "# This may take up to 10 minutes\n",
    "df['essay0'] = df['essay0'].progress_apply(split_incorrect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['long_words'] = df['essay0'].progress_apply(get_npoly)\n",
    "df['flesch'] = df['essay0'].progress_apply(get_flesch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this will the main data file for the rest of the analysis\n",
    "df.to_csv('compressed_okcupid.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
