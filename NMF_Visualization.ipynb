{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-920f2ab46070>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#General Imports\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\numpy\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    150\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfft\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpolynomial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mctypeslib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\numpy\\random\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[1;31m# add these for module-freeze analysis (like PyInstaller)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_pickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_common\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_bounded_integers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python38-32\\lib\\site-packages\\numpy\\random\\_pickle.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmtrand\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomState\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_philox\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPhilox\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_pcg64\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPCG64\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_sfc64\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSFC64\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m_bit_generator.pxd\u001b[0m in \u001b[0;36minit numpy.random.mtrand\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m_bit_generator.pyx\u001b[0m in \u001b[0;36minit numpy.random._bit_generator\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hp\\appdata\\local\\programs\\python\\python38-32\\lib\\importlib\\_bootstrap.py\u001b[0m in \u001b[0;36mparent\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#General Imports\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "from nmf_utils import nmf_labels, nmf_inspect\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "%matplotlib inline\n",
    "#from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>age</th>\n",
       "      <th>essay0</th>\n",
       "      <th>edu</th>\n",
       "      <th>fit</th>\n",
       "      <th>race_ethnicity</th>\n",
       "      <th>height_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>about me:i would love to think that i was some...</td>\n",
       "      <td>High School or less</td>\n",
       "      <td>not_fit</td>\n",
       "      <td>multiple</td>\n",
       "      <td>not_short</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>i am a chef: this is what that means.1. i am a...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>not_fit</td>\n",
       "      <td>White</td>\n",
       "      <td>not_short</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  age                                             essay0  \\\n",
       "0           0   22  about me:i would love to think that i was some...   \n",
       "1           1   35  i am a chef: this is what that means.1. i am a...   \n",
       "\n",
       "                   edu      fit race_ethnicity height_group  \n",
       "0  High School or less  not_fit       multiple    not_short  \n",
       "1              unknown  not_fit          White    not_short  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 2019\n",
    "#Number of topics\n",
    "K = 24\n",
    "#Load the processed data\n",
    "profiles = pd.read_csv('profiles_filtered.csv')\n",
    "profiles.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up variable in case we switch to different essay in future\n",
    "profile_section_to_use = 'essay0'\n",
    "documents = profiles[profile_section_to_use]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing text by TF-IDF...\n",
      "Our transformed text has 20576 rows and 2000 columns.\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_features=2000, stop_words='english', ngram_range=(1,3))\n",
    "\n",
    "print(\"Vectorizing text by TF-IDF...\")\n",
    "tfidf_text = tfidf_vectorizer.fit_transform(documents)\n",
    "\n",
    "tmp = tfidf_text.get_shape()\n",
    "print(\"Our transformed text has\", tmp[0], \"rows and\", tmp[1], \"columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing NMF on vectors...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# This section may be jumped if simply loading existing saved model\n",
    "ntopics = 24\n",
    "model = NMF(n_components=ntopics, \n",
    "            alpha=.1, \n",
    "            l1_ratio=.5, \n",
    "            init='nndsvd', random_state=seed)\n",
    "\n",
    "print('Performing NMF on vectors...')\n",
    "nmf = model.fit(tfidf_text)\n",
    "nmf_topics = nmf.components_\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_filename = 'nmf_model.sav'\n",
    "pickle.dump(model, open(nmf_filename, 'wb'))\n",
    "nmf_profile_topics= nmf.transform(tfidf_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions to help visualize topic distributions\n",
    "def common_topics_bars(topics):\n",
    "    popularity = pd.DataFrame(topics).mean()\n",
    "    popularity = popularity.rename_axis('Topic')\n",
    "    popularity = popularity.sort_values(ascending=False)\n",
    "    popularity.plot.bar(title='Topic popularity')\n",
    "    plt.savefig('barplot.png')\n",
    "    return\n",
    "\n",
    "def rank_groups(data, trait, topic):\n",
    "    groups = data[trait].value_counts().index.values\n",
    "    result = {}\n",
    "    \n",
    "    for g in groups:\n",
    "        result[g] = data[data[trait] == g][topic].mean()\n",
    "    \n",
    "    r = pd.DataFrame.from_dict(result, orient='index')\n",
    "    r.columns = [topic]\n",
    "    r = r.sort_values(by=topic, ascending=False)\n",
    "    \n",
    "    return r.round(3)\n",
    "\n",
    "def top_topics(data, trait, value, n_top_topics=3, distinctive=False):\n",
    "    topics = [col for col in data if col.startswith('topic_')]\n",
    "    vals = {}\n",
    "    means = {}\n",
    "    if distinctive:\n",
    "        for t in topics:\n",
    "            means[t] = data[t].mean()\n",
    "    else:\n",
    "        for t in topics:\n",
    "            means[t] = 1\n",
    "    \n",
    "    data = data[data[trait] == value]\n",
    "    \n",
    "    for t in topics:\n",
    "        vals[t] = data[t].mean() / means[t]\n",
    "    vals = pd.DataFrame.from_dict(vals, orient='index')    \n",
    "    vals = vals.sort_values(by=0, ascending=False).head(n_top_topics)\n",
    "\n",
    "    return list(vals.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use this section to generate the top topics for each categorical variable\n",
    "nmf_topic_info = pd.DataFrame(nmf_profile_topics).add_prefix('topic_')\n",
    "nmf_together = profiles.merge(nmf_topic_info, left_index=True, right_index=True)\n",
    "#We output this as a csv for generating future analysis\n",
    "#nmf_together.to_csv('nmf_topics_profiles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['topic_5', 'topic_20', 'topic_21', 'topic_18', 'topic_19']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_topics(data=nmf_together, trait='edu', value='High School or less', n_top_topics=5, distinctive=True)\n",
    "#We can detect the top topics in the same way for the other topics too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test For Differences in Popularity of Topics grouped by Categorical Variables\n",
    "\n",
    "def _levels(demographics, d_levels=None, print_levels=False):\n",
    "    \"\"\"The demographic levels to iterate over\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    demographics : pd.Series\n",
    "        Demographic labels\n",
    "    d_levels : list, default None\n",
    "        The specific demographic levels desired\n",
    "    print_levels : bool, default False\n",
    "        Whether to print the demographic levels\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    levels : iterable\n",
    "        The unique (sorted) levels in `demographics`\n",
    "    \"\"\"\n",
    "    levels = demographics.unique()\n",
    "    if d_levels:\n",
    "        assert set(d_levels).issubset(levels)\n",
    "        levels = d_levels\n",
    "    levels.sort()\n",
    "    if print_levels:\n",
    "        print('Levels (in order):', levels, end='\\n\\n')\n",
    "    return levels\n",
    "\n",
    "def _multinomial(corpus, kwargs):\n",
    "    \"\"\"Tokens counts by document using the spaCy tokenizer\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    corpus : array-like\n",
    "        A collection of documents\n",
    "    kwargs : dict or None\n",
    "        Keyword arguments of variable length\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X : scipy.sparse.csr.csr_matrix\n",
    "        The multinomial representation shape (n_samples, n_features)\n",
    "    v : list\n",
    "        Vocabulary\n",
    "    \"\"\"\n",
    "    if kwargs:\n",
    "        cv = CountVectorizer(tokenizer=spacy_tokenize, **kwargs)\n",
    "    else:\n",
    "        cv = CountVectorizer(tokenizer=spacy_tokenize)\n",
    "    X = cv.fit_transform(corpus)\n",
    "    v = cv.get_feature_names()\n",
    "    return X, v\n",
    "\n",
    "\n",
    "        \n",
    "def subset_df(df, col, vals):\n",
    "    \"\"\"Return a subset of `df` based on particular `vals` for `col`\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Input DataFrame\n",
    "    col : str\n",
    "        Valid column name\n",
    "    vals : list\n",
    "        Values to subset on\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    subset : pd.DataFrame\n",
    "        The rows in `df` with values in `val` for `col`\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    subset = df[df[col].isin(vals)]\n",
    "    return subset\n",
    "\n",
    "def group_pct(df, demographic):\n",
    "    \"\"\"Calculate the percentage of users in each `demographic` level\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Where applicable, this should be a subset of the original DataFrame and \n",
    "        should include a `group` column corresponding to the NMF groupings\n",
    "    demographic : str\n",
    "        Valid column name\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    by_dg : pd.DataFrame\n",
    "        Including `demographic` levels and `group` percentages\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    by_dg = pd.DataFrame({'count' :\n",
    "                          df.groupby([demographic, 'group'])['group'].count()}).reset_index()\n",
    "    by_d = by_dg.groupby(demographic, as_index=False)['count'].sum()\n",
    "    by_dg = pd.merge(by_dg, by_d, on=demographic)\n",
    "    by_dg['pct'] = by_dg.count_x / by_dg.count_y\n",
    "    return by_dg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Generating NMF Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part of the code is largely derived from the work of Juan Shishido and the University of Michigan, which were referenced in the readme for this repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, we generate the topics and assign some meaning to them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'feature_vectors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-a099f6258cb8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#The major part of the algorithm- can take some time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mspecs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'stop_words'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;34m'english'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ngram_range'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'min_df'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[1;36m0.005\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcounts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtfidf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocab\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeature_vectors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0messay0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspecs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'feature_vectors' is not defined"
     ]
    }
   ],
   "source": [
    "#The major part of the algorithm- can take some time\n",
    "specs = {'stop_words' : 'english', 'ngram_range' : (1, 3), 'min_df' : 0.005}\n",
    "counts, tfidf, vocab = feature_vectors(df.essay0, specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 25\n",
    "nmf_inspect(tfidf, vocab, k_vals=[K], n_words=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'Reach Out!', 1: 'Relocated', 2: 'About Me', 3: 'Hesitation', 4: 'Casual', 5: 'The City', 6: 'Novelty', 7: 'Cool', 8: 'Likes', 9: 'Passions', 10: 'Easy Going', 11: 'Region', 12: 'Seeking', 13: 'Thoughts', 14: 'Fun', 15: 'New Here', 16: 'Travel', 17: 'Self-summary', 18: 'Nots', 19: 'Growing Up', 20: 'Carpe Diem', 21: 'Good Company', 22: 'Hobbies', 23: 'Cultural Interests', 24: 'Ambitious'}\n"
     ]
    }
   ],
   "source": [
    "#These labels are based on the categories as assessed by Juan Shishido, then modified by me\n",
    "labels=['Reach Out!','Relocated', 'About Me', 'Hesitation', 'Casual', 'The City',\n",
    "       'Novelty', 'Cool', 'Likes', 'Passions', 'Easy Going', 'Region', 'Seeking', 'Thoughts', 'Fun', 'New Here',\n",
    "        'Travel','Self-summary', 'Nots', 'Growing Up','Carpe Diem', 'Good Company','Hobbies',\n",
    "        'Cultural Interests', 'Ambitious']\n",
    "\n",
    "label_dict = {}\n",
    "for c, value in enumerate(labels):\n",
    "    label_dict[c] = value\n",
    "print(label_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, we find a way of calculating and visualizing these topic distributions across our 4 chosen demographic variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(group_num):\n",
    "    \"\"\"\n",
    "    Returns the assigned label in the label_dict\n",
    "    \n",
    "    Parameters:\n",
    "    ---------\n",
    "    group_num: integer\n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    label: str\n",
    "    \n",
    "    \"\"\"\n",
    "    return label_dict[group_num]\n",
    "\n",
    "def format_df(df, demog, tfidf): \n",
    "    \"\"\"\n",
    "    Creates a separate dataframe for each topic value from dataframe\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    df: DataFrame\n",
    "        original data frame for analysis\n",
    "    \n",
    "    group: str\n",
    "        name of categorical variable\n",
    "    \n",
    "    tfidf- TF-IDF object\n",
    "        to be used in the calculation\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    ordered_df: DataFraeme\n",
    "        Dataframe suitably adjusted for final visualization\n",
    "    \"\"\"\n",
    "    \n",
    "    # Add a column to dataframe based on topic model label\n",
    "    df['group'] = nmf_labels(tfidf, k=K)\n",
    "    # Now get the data subsetted by the categorical variable\n",
    "    subset = subset_df(df, demog, df[demog].unique())\n",
    "    #\n",
    "    grouped = group_pct(subset, demog)\n",
    "    percent_only = grouped.drop(['count_x', 'count_y'], axis=1)\n",
    "    #percent_only\n",
    "    pivoted = percent_only.pivot(index='group', columns=demog)\n",
    "    pivoted['max_value'] = pivoted.max(axis=1)\n",
    "    ordered_df = pivoted.sort_values(by='max_value', ascending=True)\n",
    "    #Getting rid of the multi-line index\n",
    "    ordered_df.columns = ordered_df.columns.droplevel(0)\n",
    "    ordered_df = ordered_df.reset_index().rename_axis(None, axis=1)\n",
    "    #Renaming the max\n",
    "    ordered_df = ordered_df.rename(columns={'':'max'})\n",
    "    #Linking to label\n",
    "    ordered_df['label'] = ordered_df['group'].apply(get_label)\n",
    "    return ordered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'NMF' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-85e4b1633759>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mheight_df\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mformat_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'height_group'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtfidf_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-30-f3efbf46cdeb>\u001b[0m in \u001b[0;36mformat_df\u001b[1;34m(df, demog, tfidf)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;31m# Add a column to dataframe based on topic model label\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m     \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'group'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnmf_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtfidf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m     \u001b[1;31m# Now get the data subsetted by the categorical variable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[0msubset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubset_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdemog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdemog\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Dropbox\\Learning\\Chicago\\Courses\\Thesis\\github_thesis\\nmf_utils.py\u001b[0m in \u001b[0;36mnmf_labels\u001b[1;34m(tfidfmatrix, k)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mReturns\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mcount\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcsr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcsr_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0mmultinomial\u001b[0m \u001b[0mrepresentation\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mtfidf\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcsr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcsr_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'NMF' is not defined"
     ]
    }
   ],
   "source": [
    "height_df= format_df(df, 'height_group', tfidf_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height_df, race_df, edu_df, fit_df= format_df(df, 'height_group', tfidf),\n",
    "format_df(df, 'race_ethnicity', tfidf),format_df(df, 'edu', tfidf), \n",
    "format_df(df, 'fit', tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Abstracting these four into a function\n",
    "my_range=range(1,len(fit_df.index)+1)\n",
    "fig, ax = plt.subplots(figsize=(18, 15))\n",
    "ttl = ax.title\n",
    "ttl.set_position([.5, 1.05])\n",
    "\n",
    "# The vertival plot is made using the hline function\n",
    "# I load the seaborn library only to benefit the nice looking feature\n",
    "import seaborn as sns\n",
    "plt.hlines(y=my_range, xmin=0, xmax=ordered_df['max'], color='Gray')\n",
    "plt.plot(ordered_df['fit'], my_range, \"o\", markersize=20, color='blue')\n",
    "plt.plot(ordered_df['not_fit'], my_range, \"o\", markersize=20, color='red')\n",
    "plt.rc('ytick',labelsize=28)\n",
    "plt.rc('xtick',labelsize=28)\n",
    "# Add titles and axis names\n",
    "plt.yticks(my_range, ordered_df['label'])\n",
    "plt.title(\"Topics in OkCupid Male Self-Introductions Across Levels of {}\".format(), loc='center', fontsize=40)\n",
    "plt.xlabel('Proportion of Users Using This Topic', fontsize=32)\n",
    "plt.ylabel('Topics Inferred from Essay',fontsize=32)\n",
    "maroon_patch = mpatches.Patch(color='red', label='Fit')\n",
    "blue_patch = mpatches.Patch(color='blue', label='Not Fit')\n",
    "plt.legend(handles=[maroon_patch, blue_patch], loc='center right', fontsize='xx-large', borderpad=2)\n",
    "plt.savefig('fit.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot for Education Levels\n",
    "ordered_df = edu_df\n",
    "\n",
    "my_range=range(1,len(ordered_df.index)+1)\n",
    "fig, ax = plt.subplots(figsize=(18, 15))\n",
    "ttl = ax.title\n",
    "ttl.set_position([.5, 1.05])\n",
    "\n",
    "# The vertival plot is made using the hline function\n",
    "# I load the seaborn library only to benefit the nice looking feature\n",
    "import seaborn as sns\n",
    "plt.hlines(y=my_range, xmin=0, xmax=ordered_df['max'], color='Gray')\n",
    "plt.plot(ordered_df['High School or less'], my_range, \"o\", markersize=20, color='blue')\n",
    "plt.plot(ordered_df['More than High School'], my_range, \"o\", markersize=20, color='red')\n",
    "plt.rc('ytick',labelsize=28)\n",
    "plt.rc('xtick',labelsize=28)\n",
    "# Add titles and axis names\n",
    "plt.yticks(my_range, ordered_df['label'])\n",
    "plt.title(\"Topics in OkCupid Male Self-Introductions Across Education Levels\", loc='center', fontsize=40)\n",
    "plt.xlabel('Proportion of Users Using This Topic', fontsize=32)\n",
    "plt.ylabel('Topics Inferred from Essay',fontsize=32)\n",
    "maroon_patch = mpatches.Patch(color='red', label='More than High School')\n",
    "blue_patch = mpatches.Patch(color='blue', label='Less than High School')\n",
    "plt.legend(handles=[maroon_patch, blue_patch], loc='center right', fontsize='xx-large', borderpad=2)\n",
    "plt.savefig('opinions.png', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot for Fitness Levels\n",
    "ordered_df = fit_df\n",
    "\n",
    "my_range=range(1,len(fit_df.index)+1)\n",
    "fig, ax = plt.subplots(figsize=(18, 15))\n",
    "ttl = ax.title\n",
    "ttl.set_position([.5, 1.05])\n",
    "\n",
    "# The vertival plot is made using the hline function\n",
    "# I load the seaborn library only to benefit the nice looking feature\n",
    "import seaborn as sns\n",
    "plt.hlines(y=my_range, xmin=0, xmax=ordered_df['max'], color='Gray')\n",
    "plt.plot(ordered_df['fit'], my_range, \"o\", markersize=20, color='blue')\n",
    "plt.plot(ordered_df['not_fit'], my_range, \"o\", markersize=20, color='red')\n",
    "plt.rc('ytick',labelsize=28)\n",
    "plt.rc('xtick',labelsize=28)\n",
    "# Add titles and axis names\n",
    "plt.yticks(my_range, ordered_df['label'])\n",
    "plt.title(\"Topics in OkCupid Male Self-Introductions Across Fitness Levels\", loc='center', fontsize=40)\n",
    "plt.xlabel('Proportion of Users Using This Topic', fontsize=32)\n",
    "plt.ylabel('Topics Inferred from Essay',fontsize=32)\n",
    "maroon_patch = mpatches.Patch(color='red', label='Fit')\n",
    "blue_patch = mpatches.Patch(color='blue', label='Not Fit')\n",
    "plt.legend(handles=[maroon_patch, blue_patch], loc='center right', fontsize='xx-large', borderpad=2)\n",
    "plt.savefig('fit.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The Plot for Height\n",
    "ordered_df = height_df\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "my_range=range(1,len(ordered_df.index)+1)\n",
    "fig, ax = plt.subplots(figsize=(18, 15))\n",
    "ttl = ax.title\n",
    "ttl.set_position([.5, 1.05])\n",
    "\n",
    "# The vertival plot is made using the hline function\n",
    "# I load the seaborn library only to benefit the nice looking feature\n",
    "import seaborn as sns\n",
    "plt.hlines(y=my_range, xmin=0, xmax=ordered_df['max'], color='Gray')\n",
    "plt.plot(ordered_df['short'], my_range, \"o\", markersize=20, color='blue')\n",
    "plt.plot(ordered_df['not_short'], my_range, \"o\", markersize=20, color='red')\n",
    "plt.rc('ytick',labelsize=28)\n",
    "plt.rc('xtick',labelsize=28)\n",
    "# Add titles and axis names\n",
    "plt.yticks(my_range, ordered_df['label'])\n",
    "plt.title(\"Topics in OkCupid Male Self-Introductions Across Height Groups\", loc='center', fontsize=40)\n",
    "plt.xlabel('Proportion of Users Using This Topic', fontsize=32)\n",
    "plt.ylabel('Topics Inferred from Essay',fontsize=32)\n",
    "maroon_patch = mpatches.Patch(color='red', label='Short')\n",
    "blue_patch = mpatches.Patch(color='blue', label='Not Short')\n",
    "plt.legend(handles=[maroon_patch, blue_patch], loc='center right', fontsize='xx-large', borderpad=2)\n",
    "plt.savefig('height.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Plot for Races\n",
    "ordered_df = race_df\n",
    "my_range=range(1,len(ordered_df.index)+1)\n",
    "fig, ax = plt.subplots(figsize=(18, 15))\n",
    "ttl = ax.title\n",
    "ttl.set_position([.5, 1.05])\n",
    "\n",
    "# The vertival plot is made using the hline function\n",
    "# I load the seaborn library only to benefit the nice looking feature\n",
    "import seaborn as sns\n",
    "plt.hlines(y=my_range, xmin=0, xmax=ordered_df['max'], color='Gray')\n",
    "plt.plot(ordered_df['White'], my_range, \"o\", markersize=20, color='blue')\n",
    "plt.plot(ordered_df['Black'], my_range, \"o\", markersize=20, color='red')\n",
    "plt.plot(ordered_df['Asian'], my_range, \"o\", markersize=20, color='green')\n",
    "plt.plot(ordered_df['Latinx'], my_range, \"o\", markersize=20, color='cyan')\n",
    "plt.plot(ordered_df['multiple'], my_range, \"o\", markersize=20, color='magenta')\n",
    "plt.rc('ytick',labelsize=28)\n",
    "plt.rc('xtick',labelsize=28)\n",
    "# Add titles and axis names\n",
    "plt.yticks(my_range, ordered_df['label'])\n",
    "plt.title(\"Topics in OkCupid Male Self-Introductions Across Racial Groups\", loc='center', fontsize=40)\n",
    "plt.xlabel('Proportion of Users Using This Topic', fontsize=32)\n",
    "plt.ylabel('Topics Inferred from Essay',fontsize=32)\n",
    "blue_patch = mpatches.Patch(color='blue', label='White')\n",
    "maroon_patch = mpatches.Patch(color='red', label='Black')\n",
    "green_patch = mpatches.Patch(color='green', label='Asian')\n",
    "cyan_patch = mpatches.Patch(color='cyan', label='Latinx')\n",
    "magenta_patch = mpatches.Patch(color='magenta', label='multiple')\n",
    "plt.legend(handles=[maroon_patch, blue_patch, green_patch, cyan_patch, magenta_patch], loc='center right', fontsize='xx-large', borderpad=2)\n",
    "plt.savefig('race.png', bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
