{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-726460ba1e20>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m#from spacy.en import English\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermutation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprint_pvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext_representation\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_levels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_multinomial\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "#General Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "import re\n",
    "from string import punctuation\n",
    "from scipy.stats import ttest_ind\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import nltk\n",
    "import pandas as pd\n",
    "#from spacy.en import English\n",
    "\n",
    "#from utils.permutation import print_pvalues\n",
    "#from utils.text_representation import _levels, _multinomial\n",
    "import nmf_visuals \n",
    "from nmf_utils import feature_vectors, nmf_labels, nmf_inspect, nmf_subset\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "#nlp = English(tagger=True, entity=False)\n",
    "\n",
    "%matplotlib inline\n",
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vectorizer = CountVectorizer(max_features=2000, stop_words='english', ngram_range=(1,3))\n",
    "\n",
    "print(\"Vectorizing text by word counts...\")\n",
    "tf_text = tf_vectorizer.fit_transform(profiles['essay0'])\n",
    "\n",
    "tmp = tf_text.get_shape()\n",
    "print(\"Our transformed text has\", tmp[0], \"rows and\", tmp[1], \"columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2019\n",
    "profiles = pd.read_csv('final_okcupid.csv').dropna(subset=['essay0'])\n",
    "profiles.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up variable in case we switch to different essay in future\n",
    "profile_section_to_use = 'essay0'\n",
    "documents = profiles[profile_section_to_use]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section may be jumped if simply loading existing saved model\n",
    "model = NMF(n_components=ntopics, \n",
    "            alpha=.1, \n",
    "            l1_ratio=.5, \n",
    "            init='nndsvd', random_state=seed)\n",
    "\n",
    "print('Performing NMF on vectors...')\n",
    "nmf = model.fit(tfidf_text)\n",
    "nmf_topics = nmf.components_\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_filename = 'nmf_model.sav'\n",
    "pickle.dump(model, open(nmf_filename, 'wb'))\n",
    "nmf_profile_topics= nmf.transform(tfidf_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions to help visualize topic distributions\n",
    "def common_topics_bars(topics):\n",
    "    popularity = pd.DataFrame(topics).mean()\n",
    "    popularity = popularity.rename_axis('Topic')\n",
    "    popularity = popularity.sort_values(ascending=False)\n",
    "    popularity.plot.bar(title='Topic popularity')\n",
    "    plt.savefig('barplot.png')\n",
    "    return\n",
    "\n",
    "def rank_groups(data, trait, topic):\n",
    "    groups = data[trait].value_counts().index.values\n",
    "    result = {}\n",
    "    \n",
    "    for g in groups:\n",
    "        result[g] = data[data[trait] == g][topic].mean()\n",
    "    \n",
    "    r = pd.DataFrame.from_dict(result, orient='index')\n",
    "    r.columns = [topic]\n",
    "    r = r.sort_values(by=topic, ascending=False)\n",
    "    \n",
    "    return r.round(3)\n",
    "\n",
    "def top_topics(data, trait, value, n_top_topics=3, distinctive=False):\n",
    "    topics = [col for col in data if col.startswith('topic_')]\n",
    "    vals = {}\n",
    "    means = {}\n",
    "    if distinctive:\n",
    "        for t in topics:\n",
    "            means[t] = data[t].mean()\n",
    "    else:\n",
    "        for t in topics:\n",
    "            means[t] = 1\n",
    "    \n",
    "    data = data[data[trait] == value]\n",
    "    \n",
    "    for t in topics:\n",
    "        vals[t] = data[t].mean() / means[t]\n",
    "    vals = pd.DataFrame.from_dict(vals, orient='index')    \n",
    "    vals = vals.sort_values(by=0, ascending=False).head(n_top_topics)\n",
    "\n",
    "    return list(vals.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use this section to generate the top topics for each categorical variable\n",
    "nmf_topic_info = pd.DataFrame(nmf_profile_topics).add_prefix('topic_')\n",
    "nmf_together = profiles.merge(nmf_topic_info, left_index=True, right_index=True)\n",
    "#We output this as a csv for generating future analysis\n",
    "nmf_together.to_csv('nmf_topics_profiles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions to Generate Plots\n",
    "def common_topics_bars(topics):\n",
    "    popularity = pd.DataFrame(topics).mean()\n",
    "    popularity = popularity.rename_axis('Topic')\n",
    "    popularity = popularity.sort_values(ascending=False)\n",
    "    popularity.plot.bar(title='Topic popularity')\n",
    "    plt.savefig('barplot.png')\n",
    "    return\n",
    "\n",
    "def rank_groups(data, trait, topic):\n",
    "    groups = data[trait].value_counts().index.values\n",
    "    result = {}\n",
    "    \n",
    "    for g in groups:\n",
    "        result[g] = data[data[trait] == g][topic].mean()\n",
    "    \n",
    "    r = pd.DataFrame.from_dict(result, orient='index')\n",
    "    r.columns = [topic]\n",
    "    r = r.sort_values(by=topic, ascending=False)\n",
    "    \n",
    "    return r.round(3)\n",
    "\n",
    "def top_topics(data, trait, value, n_top_topics=3, distinctive=False):\n",
    "    topics = [col for col in data if col.startswith('topic_')]\n",
    "    vals = {}\n",
    "    means = {}\n",
    "    if distinctive:\n",
    "        for t in topics:\n",
    "            means[t] = data[t].mean()\n",
    "    else:\n",
    "        for t in topics:\n",
    "            means[t] = 1\n",
    "    \n",
    "    data = data[data[trait] == value]\n",
    "    \n",
    "    for t in topics:\n",
    "        vals[t] = data[t].mean() / means[t]\n",
    "    vals = pd.DataFrame.from_dict(vals, orient='index')    \n",
    "    vals = vals.sort_values(by=0, ascending=False).head(n_top_topics)\n",
    "\n",
    "    return list(vals.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_topics_bars(profile_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Support Functions\n",
    "# Text Representation\n",
    "\n",
    "\n",
    "def _levels(demographics, d_levels=None, print_levels=False):\n",
    "    \"\"\"The demographic levels to iterate over\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    demographics : pd.Series\n",
    "        Demographic labels\n",
    "    d_levels : list, default None\n",
    "        The specific demographic levels desired\n",
    "    print_levels : bool, default False\n",
    "        Whether to print the demographic levels\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    levels : iterable\n",
    "        The unique (sorted) levels in `demographics`\n",
    "    \"\"\"\n",
    "    levels = demographics.unique()\n",
    "    if d_levels:\n",
    "        assert set(d_levels).issubset(levels)\n",
    "        levels = d_levels\n",
    "    levels.sort()\n",
    "    if print_levels:\n",
    "        print('Levels (in order):', levels, end='\\n\\n')\n",
    "    return levels\n",
    "\n",
    "def _multinomial(corpus, kwargs):\n",
    "    \"\"\"Tokens counts by document using the spaCy tokenizer\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    corpus : array-like\n",
    "        A collection of documents\n",
    "    kwargs : dict or None\n",
    "        Keyword arguments of variable length\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X : scipy.sparse.csr.csr_matrix\n",
    "        The multinomial representation shape (n_samples, n_features)\n",
    "    v : list\n",
    "        Vocabulary\n",
    "    \"\"\"\n",
    "    if kwargs:\n",
    "        cv = CountVectorizer(tokenizer=spacy_tokenize, **kwargs)\n",
    "    else:\n",
    "        cv = CountVectorizer(tokenizer=spacy_tokenize)\n",
    "    X = cv.fit_transform(corpus)\n",
    "    v = cv.get_feature_names()\n",
    "    return X, v\n",
    "\n",
    "\n",
    "        \n",
    "def subset_df(df, col, vals):\n",
    "    \"\"\"Return a subset of `df` based on particular `vals` for `col`\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Input DataFrame\n",
    "    col : str\n",
    "        Valid column name\n",
    "    vals : list\n",
    "        Values to subset on\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    subset : pd.DataFrame\n",
    "        The rows in `df` with values in `val` for `col`\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    subset = df[df[col].isin(vals)]\n",
    "    return subset\n",
    "\n",
    "def group_pct(df, demographic):\n",
    "    \"\"\"Calculate the percentage of users in each `demographic` level\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Where applicable, this should be a subset of the original DataFrame and \n",
    "        should include a `group` column corresponding to the NMF groupings\n",
    "    demographic : str\n",
    "        Valid column name\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    by_dg : pd.DataFrame\n",
    "        Including `demographic` levels and `group` percentages\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    by_dg = pd.DataFrame({'count' :\n",
    "                          df.groupby([demographic, 'group'])['group'].count()}).reset_index()\n",
    "    by_d = by_dg.groupby(demographic, as_index=False)['count'].sum()\n",
    "    by_dg = pd.merge(by_dg, by_d, on=demographic)\n",
    "    by_dg['pct'] = by_dg.count_x / by_dg.count_y\n",
    "    return by_dg\n",
    "\n",
    "def feature_vectors(corpus, kwargs=None):\n",
    "    \"\"\"Multinomial and TF-IDF representations\n",
    "\n",
    "    Paramaters\n",
    "    ----------\n",
    "    corpus : array-like\n",
    "        A collection of documents\n",
    "    kwargs : dict, default None\n",
    "        Keyword arguments of variable length\n",
    "        See sklearn.feature_extraction.text.CountVectorizer\n",
    "        for accepted keyword arguments\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    count : scipy.sparse.csr.csr_matrix\n",
    "        The multinomial representation shape (n_samples, n_features)\n",
    "    tfidf : scipy.sparse.csr.csr_matrix\n",
    "        The tf-idf representation\n",
    "    vocab : list\n",
    "        Vocabulary\n",
    "    \"\"\"\n",
    "    assert isinstance(corpus, (list, pd.Series))\n",
    "    count, vocab = _multinomial(corpus, kwargs)\n",
    "    tfidf = _tfidf(count)\n",
    "    return count, tfidf, vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Generating NMF Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part of the code is largely derived from the work of Juan Shishido and the University of Michigan, which were referenced in the readme for this repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, we generate the topics and assign some meaning to them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('compressed_okcupid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The major part of the algorithm- can take some time\n",
    "specs = {'stop_words' : 'english', 'ngram_range' : (1, 3), 'min_df' : 0.005}\n",
    "counts, tfidf, vocab = feature_vectors(df.essay0, specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 25\n",
    "nmf_inspect(tfidf, vocab, k_vals=[K], n_words=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These labels are based on the categories as assessed by Juan Shishido, then modified by me\n",
    "labels=['Reach Out!','Relocated', 'About Me', 'Hesitation', 'Casual', 'The City',\n",
    "       'Novelty', 'Cool', 'Likes', 'Passions', 'Easy Going', 'Region', 'Seeking', 'Thoughts', 'Fun', 'New Here',\n",
    "        'Travel','Self-summary', 'Nots', 'Growing Up','Carpe Diem', 'Good Company','Hobbies',\n",
    "        'Cultural Interests', 'Ambitious']\n",
    "\n",
    "label_dict = {}\n",
    "for c, value in enumerate(labels):\n",
    "    label_dict[c] = value\n",
    "print(label_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, we find a way of calculating and visualizing these topic distributions across our 4 chosen demographic variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_demog(model, feature_names, n_top_words):\n",
    "    \"\"\"For printing the `n_top_words` for each grouping\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : sklearn.decomposition.nmf.NMF\n",
    "        The NMF object\n",
    "\n",
    "    feature_names : list\n",
    "        The output from calling `TfidfVectorizer` on the users/features data\n",
    "\n",
    "    n_top_words : int\n",
    "        The top n words to print for a particular grouping\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Group %d:\" % topic_idx)\n",
    "        print(\" | \".join([feature_names[i]\n",
    "            for i in topic.argsort()[ : -n_top_words-1 : -1]]))\n",
    "        print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(group_num):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    return label_dict[group_num]\n",
    "\n",
    "def format_df(df, demog, tfidf): \n",
    "    \"\"\"\n",
    "    Creates a separate dataframe for each topic value from dataframe\n",
    "    \n",
    "    Parameters:\n",
    "    df- original data frame for analysis\n",
    "    group- name of categorical variable\n",
    "    tfidf- TF-IDF object to be used in the calculation\n",
    "    \"\"\"\n",
    "    \n",
    "    # Add a column to dataframe based on topic model label\n",
    "    df['group'] = nmf_labels(tfidf, k=K)\n",
    "    # Now get the data subsetted by the categorical variable\n",
    "    subset = subset_df(df, demog, df[demog].unique())\n",
    "    #\n",
    "    grouped = group_pct(subset, demog)\n",
    "    percent_only = grouped.drop(['count_x', 'count_y'], axis=1)\n",
    "    #percent_only\n",
    "    pivoted = percent_only.pivot(index='group', columns=demog)\n",
    "    pivoted['max_value'] = pivoted.max(axis=1)\n",
    "    ordered_df = pivoted.sort_values(by='max_value', ascending=True)\n",
    "    #Getting rid of the multi-line index\n",
    "    ordered_df.columns = ordered_df.columns.droplevel(0)\n",
    "    ordered_df = ordered_df.reset_index().rename_axis(None, axis=1)\n",
    "    #Renaming the max\n",
    "    ordered_df = ordered_df.rename(columns={'':'max'})\n",
    "    #Linking to label\n",
    "    ordered_df['label'] = ordered_df['group'].apply(get_label)\n",
    "    return ordered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height_df, race_df, edu_df, fit_df= format_df(df, 'height_group', tfidf), \n",
    "                                    format_df(df, 'race_ethnicity', tfidf), \n",
    "                                    format_df(df, 'edu', tfidf), \n",
    "                                    format_df(df, 'fit', tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot for Education Levels\n",
    "ordered_df = edu_df\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "my_range=range(1,len(ordered_df.index)+1)\n",
    "fig, ax = plt.subplots(figsize=(18, 15))\n",
    "ttl = ax.title\n",
    "ttl.set_position([.5, 1.05])\n",
    "\n",
    "# The vertival plot is made using the hline function\n",
    "# I load the seaborn library only to benefit the nice looking feature\n",
    "import seaborn as sns\n",
    "plt.hlines(y=my_range, xmin=0, xmax=ordered_df['max'], color='Gray')\n",
    "plt.plot(ordered_df['High School or less'], my_range, \"o\", markersize=20, color='blue')\n",
    "plt.plot(ordered_df['More than High School'], my_range, \"o\", markersize=20, color='red')\n",
    "plt.rc('ytick',labelsize=28)\n",
    "plt.rc('xtick',labelsize=28)\n",
    "# Add titles and axis names\n",
    "plt.yticks(my_range, ordered_df['label'])\n",
    "plt.title(\"Topics in OkCupid Male Self-Introductions Across Education Levels\", loc='center', fontsize=40)\n",
    "plt.xlabel('Proportion of Users Using This Topic', fontsize=32)\n",
    "plt.ylabel('Topics Inferred from Essay',fontsize=32)\n",
    "maroon_patch = mpatches.Patch(color='red', label='More than High School')\n",
    "blue_patch = mpatches.Patch(color='blue', label='Less than High School')\n",
    "plt.legend(handles=[maroon_patch, blue_patch], loc='center right', fontsize='xx-large', borderpad=2)\n",
    "plt.savefig('opinions.png', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot for Fitness Levels\n",
    "ordered_df = fit_df\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "my_range=range(1,len(fit_df.index)+1)\n",
    "fig, ax = plt.subplots(figsize=(18, 15))\n",
    "ttl = ax.title\n",
    "ttl.set_position([.5, 1.05])\n",
    "\n",
    "# The vertival plot is made using the hline function\n",
    "# I load the seaborn library only to benefit the nice looking feature\n",
    "import seaborn as sns\n",
    "plt.hlines(y=my_range, xmin=0, xmax=ordered_df['max'], color='Gray')\n",
    "plt.plot(ordered_df['fit'], my_range, \"o\", markersize=20, color='blue')\n",
    "plt.plot(ordered_df['not_fit'], my_range, \"o\", markersize=20, color='red')\n",
    "plt.rc('ytick',labelsize=28)\n",
    "plt.rc('xtick',labelsize=28)\n",
    "# Add titles and axis names\n",
    "plt.yticks(my_range, ordered_df['label'])\n",
    "plt.title(\"Topics in OkCupid Male Self-Introductions Across Fitness Levels\", loc='center', fontsize=40)\n",
    "plt.xlabel('Proportion of Users Using This Topic', fontsize=32)\n",
    "plt.ylabel('Topics Inferred from Essay',fontsize=32)\n",
    "maroon_patch = mpatches.Patch(color='red', label='Fit')\n",
    "blue_patch = mpatches.Patch(color='blue', label='Not Fit')\n",
    "plt.legend(handles=[maroon_patch, blue_patch], loc='center right', fontsize='xx-large', borderpad=2)\n",
    "plt.savefig('fit.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The Plot for Height\n",
    "ordered_df = height_df\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "my_range=range(1,len(ordered_df.index)+1)\n",
    "fig, ax = plt.subplots(figsize=(18, 15))\n",
    "ttl = ax.title\n",
    "ttl.set_position([.5, 1.05])\n",
    "\n",
    "# The vertival plot is made using the hline function\n",
    "# I load the seaborn library only to benefit the nice looking feature\n",
    "import seaborn as sns\n",
    "plt.hlines(y=my_range, xmin=0, xmax=ordered_df['max'], color='Gray')\n",
    "plt.plot(ordered_df['short'], my_range, \"o\", markersize=20, color='blue')\n",
    "plt.plot(ordered_df['not_short'], my_range, \"o\", markersize=20, color='red')\n",
    "plt.rc('ytick',labelsize=28)\n",
    "plt.rc('xtick',labelsize=28)\n",
    "# Add titles and axis names\n",
    "plt.yticks(my_range, ordered_df['label'])\n",
    "plt.title(\"Topics in OkCupid Male Self-Introductions Across Height Groups\", loc='center', fontsize=40)\n",
    "plt.xlabel('Proportion of Users Using This Topic', fontsize=32)\n",
    "plt.ylabel('Topics Inferred from Essay',fontsize=32)\n",
    "maroon_patch = mpatches.Patch(color='red', label='Short')\n",
    "blue_patch = mpatches.Patch(color='blue', label='Not Short')\n",
    "plt.legend(handles=[maroon_patch, blue_patch], loc='center right', fontsize='xx-large', borderpad=2)\n",
    "plt.savefig('height.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Plot for Races\n",
    "ordered_df = race_df\n",
    "my_range=range(1,len(ordered_df.index)+1)\n",
    "fig, ax = plt.subplots(figsize=(18, 15))\n",
    "ttl = ax.title\n",
    "ttl.set_position([.5, 1.05])\n",
    "\n",
    "# The vertival plot is made using the hline function\n",
    "# I load the seaborn library only to benefit the nice looking feature\n",
    "import seaborn as sns\n",
    "plt.hlines(y=my_range, xmin=0, xmax=ordered_df['max'], color='Gray')\n",
    "plt.plot(ordered_df['White'], my_range, \"o\", markersize=20, color='blue')\n",
    "plt.plot(ordered_df['Black'], my_range, \"o\", markersize=20, color='red')\n",
    "plt.plot(ordered_df['Asian'], my_range, \"o\", markersize=20, color='green')\n",
    "plt.plot(ordered_df['Latinx'], my_range, \"o\", markersize=20, color='cyan')\n",
    "plt.plot(ordered_df['multiple'], my_range, \"o\", markersize=20, color='magenta')\n",
    "plt.rc('ytick',labelsize=28)\n",
    "plt.rc('xtick',labelsize=28)\n",
    "# Add titles and axis names\n",
    "plt.yticks(my_range, ordered_df['label'])\n",
    "plt.title(\"Topics in OkCupid Male Self-Introductions Across Racial Groups\", loc='center', fontsize=40)\n",
    "plt.xlabel('Proportion of Users Using This Topic', fontsize=32)\n",
    "plt.ylabel('Topics Inferred from Essay',fontsize=32)\n",
    "blue_patch = mpatches.Patch(color='blue', label='White')\n",
    "maroon_patch = mpatches.Patch(color='red', label='Black')\n",
    "green_patch = mpatches.Patch(color='green', label='Asian')\n",
    "cyan_patch = mpatches.Patch(color='cyan', label='Latinx')\n",
    "magenta_patch = mpatches.Patch(color='magenta', label='multiple')\n",
    "plt.legend(handles=[maroon_patch, blue_patch, green_patch, cyan_patch, magenta_patch], loc='center right', fontsize='xx-large', borderpad=2)\n",
    "plt.savefig('race.png', bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
